{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy import *\n",
    "import matplotlib.pylab as plt\n",
    "# import operator\n",
    "import pyscf\n",
    "from pyscf import gto, scf, dft, tddft, data\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions (linewidth=300)\n",
    "\n",
    "elements = ['H' , 'He', 'Li', 'Be', 'B' , 'C' , 'N' , 'O' , 'F' , 'Ne',\n",
    "    'Na', 'Mg', 'Al', 'Si', 'P' , 'S' , 'Cl', 'Ar', 'K' , 'Ca',\n",
    "    'Sc', 'Ti', 'V' , 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y' , 'Zr',\n",
    "    'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',\n",
    "    'Sb', 'Te', 'I' , 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd',\n",
    "    'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb',\n",
    "    'Lu', 'Hf', 'Ta', 'W' , 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
    "    'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th',\n",
    "    'Pa', 'U' , 'Np', 'Pu'] \n",
    "hardness = [\n",
    "0.47259288,\n",
    "0.92203391,\n",
    "0.17452888,\n",
    "0.25700733,\n",
    "0.33949086,\n",
    "0.42195412,\n",
    "0.50438193,\n",
    "0.58691863,\n",
    "0.66931351,\n",
    "0.75191607,\n",
    "0.17964105,\n",
    "0.22157276,\n",
    "0.26348578,\n",
    "0.30539645,\n",
    "0.34734014,\n",
    "0.38924725,\n",
    "0.43115670,\n",
    "0.47308269,\n",
    "0.17105469,\n",
    "0.20276244,\n",
    "0.21007322,\n",
    "0.21739647,\n",
    "0.22471039,\n",
    "0.23201501,\n",
    "0.23933969,\n",
    "0.24665638,\n",
    "0.25398255,\n",
    "0.26128863,\n",
    "0.26859476,\n",
    "0.27592565,\n",
    "0.30762999,\n",
    "0.33931580,\n",
    "0.37235985,\n",
    "0.40273549,\n",
    "0.43445776,\n",
    "0.46611708,\n",
    "0.15585079,\n",
    "0.18649324,\n",
    "0.19356210,\n",
    "0.20063311,\n",
    "0.20770522,\n",
    "0.21477254,\n",
    "0.22184614,\n",
    "0.22891872,\n",
    "0.23598621,\n",
    "0.24305612,\n",
    "0.25013018,\n",
    "0.25719937,\n",
    "0.28784780,\n",
    "0.31848673,\n",
    "0.34912431,\n",
    "0.37976593,\n",
    "0.41040808,\n",
    "0.44105777,\n",
    "0.05019332,\n",
    "0.06762570,\n",
    "0.08504445,\n",
    "0.10247736,\n",
    "0.11991105,\n",
    "0.13732772,\n",
    "0.15476297,\n",
    "0.17218265,\n",
    "0.18961288,\n",
    "0.20704760,\n",
    "0.22446752,\n",
    "0.24189645,\n",
    "0.25932503,\n",
    "0.27676094,\n",
    "0.29418231,\n",
    "0.31159587,\n",
    "0.32902274,\n",
    "0.34592298,\n",
    "0.36388048,\n",
    "0.38130586,\n",
    "0.39877476,\n",
    "0.41614298,\n",
    "0.43364510,\n",
    "0.45104014,\n",
    "0.46848986,\n",
    "0.48584550,\n",
    "0.12526730,\n",
    "0.14268677,\n",
    "0.16011615,\n",
    "0.17755889,\n",
    "0.19497557,\n",
    "0.21240778,\n",
    "0.07263525,\n",
    "0.09422158,\n",
    "0.09920295,\n",
    "0.10418621,\n",
    "0.14235633,\n",
    "0.16394294,\n",
    "0.18551941,\n",
    "0.22370139]\n",
    "#in Hartree\n",
    "HARDNESS = dict(zip(elements,hardness))\n",
    "def Hardness (atom_id):\n",
    "    atom = mol.atom_pure_symbol(atom_id)\n",
    "    return HARDNESS[atom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = '\\\n",
    "# C         -3.15617        2.59898        0.79547;\\\n",
    "# C         -1.79169        2.11570        0.42917;\\\n",
    "# O         -0.80893        2.56621        0.99508;\\\n",
    "# H         -1.66947        1.36193       -0.34183;\\\n",
    "# H         -3.35300        2.38970        1.86780;\\\n",
    "# H         -3.91803        2.07820        0.17854;\\\n",
    "# H         -3.22824        3.69190        0.61449',\\\n",
    "# basis = 'def2-SVP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = 'O         -4.89126        3.29770        0.00029;\\\n",
    "# H         -3.49307        3.28429       -0.00328;\\\n",
    "# H         -5.28213        2.58374        0.75736', basis = 'def2-SVP', symmetry = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyscf.gto.mole.Mole at 0x7f98220c7bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = gto.Mole()\n",
    "mol.build(atom = '\\\n",
    "C         -4.89126        3.29770        0.00029;\\\n",
    "O         -3.49307        3.28429       -0.00328;\\\n",
    "H         -5.28213        2.58374        0.75736;\\\n",
    "H         -5.28213        3.05494       -1.01161;\\\n",
    "H         -5.23998        4.31540        0.27138;\\\n",
    "H         -3.22959        2.35981       -0.24953',\\\n",
    "basis = 'def2-SVP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = '\\\n",
    "# C         -1.44673        2.80824       -0.07813;\\\n",
    "# O         -1.78998        3.80792       -0.69188;\\\n",
    "# N         -1.18291        1.66325       -0.74926;\\\n",
    "# N         -1.33221        2.85136        1.26946;\\\n",
    "# H         -1.53168        3.72026        1.78651;\\\n",
    "# H         -1.04365        2.01512        1.79805;\\\n",
    "# H         -1.26824        1.62382       -1.77554;\\\n",
    "# H         -0.89270        0.81388       -0.24298'\\\n",
    "# , basis = 'def2-SVP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -115.596846791624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-115.5968467916237"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = dft.RKS(mol) \n",
    "mf.conv_tol = 1e-9\n",
    "mf.grids.level = 3     # 0-9, big number for large mesh grids, default is 3\n",
    "mf.xc = 'wb97x'\n",
    "mf.kernel()  #single point energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf = scf.RHF(mol) \n",
    "# mf.conv_tol = 1e-9\n",
    "# mf.kernel()  #single point energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIS = pyscf.tdscf.rhf.CIS(mf)\n",
    "# CIS.nstates = 5\n",
    "# CIS.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excited State energies (eV)\n",
      "[ 7.60448706  9.60736875  9.65608887 10.54993156 10.84667365]\n",
      "Pyscf time = 5.1782\n"
     ]
    }
   ],
   "source": [
    "td = tddft.TDA(mf)\n",
    "td.nstates = 5\n",
    "start = time.time()\n",
    "td.kernel()    #compute first few excited states.\n",
    "end = time.time()\n",
    "print ('Pyscf time =', round(end-start,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "vind, hdiag = td.gen_vind(mf)\n",
    "print (np.shape(hdiag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf.analyze()\n",
    "#MO energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf.mulliken_pop_meta_lowdin_ao()\n",
    "#population analysis\n",
    "#mf.mulliken_pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether a is symmetric\n",
    "# def check_symmetric(a, tol=1e-12):\n",
    "#     return np.all(np.abs(a-a.T) < tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle(object):\n",
    "    \n",
    "\n",
    "    c = 10\n",
    "    \n",
    "    def __init__(self, length, height):\n",
    "        self.length = length\n",
    "        self.height = height\n",
    "        \n",
    "    \n",
    "    def area(self):\n",
    "        self.age = 6\n",
    "        self.degree = 100\n",
    "#         print(self.length * self.height)\n",
    "    \n",
    "#     @classmethod\n",
    "#     def volume(cls):\n",
    "#         cls.a = 4\n",
    "#         cls.b = 9\n",
    "#         print(cls.c)\n",
    "#         # it can create new object!\n",
    "\n",
    "#     @classmethod\n",
    "#     def kernel(cls):\n",
    "# #         print(cls.length)\n",
    "#         print(cls.a)\n",
    "#         print(cls.length)\n",
    "#         print(cls.b)\n",
    "#         print(cls.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of overlap matrix (48, 48)\n"
     ]
    }
   ],
   "source": [
    "def matrix_power (S,a):\n",
    "    s,ket = np.linalg.eigh(S)\n",
    "    # S = mf.get_ovlp() #.get_ovlp() is basis overlap matrix\n",
    "    # S = np.dot(np.linalg.inv(c.T), np.linalg.inv(c))\n",
    "    # #s are eigenvalues, must be all positive\n",
    "    # #each column of ket is a eigenket\n",
    "    s = s**a\n",
    "    X = np.linalg.multi_dot([ket,np.diag(s),ket.T])\n",
    "    #X == S^1/2\n",
    "    return X\n",
    "\n",
    "def orthonormalize (C):\n",
    "    X = matrix_power(mf.get_ovlp(), 0.5)\n",
    "    # X = S^1/2\n",
    "    C = np.dot(X,C)\n",
    "    return C\n",
    "\n",
    "print ('shape of overlap matrix', np.shape(mf.get_ovlp()))\n",
    "\n",
    "C = mf.mo_coeff\n",
    "\n",
    "# mf.mo_coeff is the coefficient matrix\n",
    "C = orthonormalize (C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Natm = mol.natm\n",
    "MOe = mf.mo_energy  \n",
    "#an array of MO energies, in Hartree\n",
    "\n",
    "vind, hdiag = td.gen_vind(mf)\n",
    "# vind (V) = A*V\n",
    "def matrix_vector(V):\n",
    "    return vind(V.T).T\n",
    "\n",
    "mo_occ = mf.mo_occ\n",
    "\n",
    "n_occ = len(np.where(mo_occ > 0)[0])\n",
    "#mf.mo_occ is an array of occupance [2,2,2,2,2,0,0,0,0.....]\n",
    "n_vir = len(np.where(mo_occ == 0)[0])\n",
    "\n",
    "N_bf = len(mo_occ)\n",
    "R = pyscf.gto.mole.inter_distance(mol, coords=None)\n",
    "#Inter-particle distance array\n",
    "# unit == ’Bohr’, Its value is 5.29177210903(80)×10^(−11) m\n",
    "########################################################################\n",
    "\n",
    "N_bf = mf.mo_occ.size\n",
    "#number of atomic orbitals\n",
    "# print('N_bf', N_bf)\n",
    "R = pyscf.gto.mole.inter_distance(mol, coords=None)\n",
    "\n",
    "# a_x = 0.38\n",
    "# beta1= 1.86\n",
    "# beta2=0\n",
    "# alpha1= 0.9\n",
    "# alpha2=0\n",
    "# beta = beta1 + beta2 * a_x\n",
    "# alpha = alpha1 + alpha2 * a_x\n",
    "\n",
    "# wb97x\n",
    "a_x, beta, alpha = 0.56, 8.00, 4.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat \\eta matrix\n",
    "a = [Hardness(atom_id) for atom_id in range (Natm)]\n",
    "a = np.asarray(a).reshape(1,-1)\n",
    "eta = (a+a.T)/2\n",
    "\n",
    "# creat GammaK and GammaK matrix\n",
    "GammaJ = (R**beta + (a_x * eta)**(-beta))**(-1/beta)\n",
    "GammaK = (R**alpha + eta**(-alpha)) **(-1/alpha)\n",
    "\n",
    "Natm = mol.natm\n",
    "def generateQ ():\n",
    "    aoslice = mol.aoslice_by_atom()\n",
    "    q = np.zeros([Natm, N_bf, N_bf])\n",
    "    #N_bf is number Atomic orbitals, n_occ+n_vir, q is same size with C\n",
    "    for atom_id in range (0, Natm):\n",
    "        shst, shend, atstart, atend = aoslice[atom_id]\n",
    "        q[atom_id,:, :] = np.dot(C[atstart:atend, :].T, C[atstart:atend, :])\n",
    "    return q\n",
    "\n",
    "q_tensors = generateQ()\n",
    "\n",
    "\n",
    "q_tensor_ij = np.zeros((Natm, n_occ, n_occ))\n",
    "q_tensor_ij[:,:,:] = q_tensors[:, :n_occ,:n_occ]\n",
    "\n",
    "q_tensor_ab = np.zeros((Natm, n_vir, n_vir))\n",
    "q_tensor_ab[:,:,:] = q_tensors[:, n_occ:,n_occ:]\n",
    "\n",
    "q_tensor_ia = np.zeros((Natm, n_occ, n_vir))\n",
    "q_tensor_ia[:,:,:] = q_tensors[:, :n_occ,n_occ:]\n",
    "\n",
    "\n",
    "Q_K = einsum('Bjb, AB -> Ajb', q_tensor_ia, GammaK)\n",
    "Q_J = einsum('Bab, AB -> Aab', q_tensor_ab, GammaJ)\n",
    "# pre-calculate and store the Q-Gamma rank 3 tensor\n",
    "\n",
    "\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.46714168 8.18163055 8.3832315  9.45187912]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def iajb_fly (V):\n",
    "    Q_K_V = einsum('Ajb, mjb -> Am', Q_K, V)\n",
    "    iajb_V = einsum('Aia, Am -> mia', q_tensor_ia, Q_K_V)\n",
    "    return iajb_V\n",
    "\n",
    "def ijab_fly (V):\n",
    "    Aab_V = einsum('Aab, mjb -> Aamj', Q_J, V)\n",
    "    #('Aab, mjb -> mjaA')\n",
    "    ijab_V = einsum('Aij, Aamj -> mia', q_tensor_ij, Aab_V)\n",
    "    #('Aij, mjaA -> mia)\n",
    "    return ijab_V\n",
    "\n",
    "delta_diag_A = hdiag.reshape(n_occ, n_vir)\n",
    "\n",
    "def delta_fly (V):\n",
    "    delta_v = einsum('ia, mia -> mia', delta_diag_A, V)\n",
    "    return delta_v\n",
    "\n",
    "def sTDA_fly (V):\n",
    "    # sTDA_A * V\n",
    "    # usually V is in shape (n_occ*n_vir, -1)\n",
    "\n",
    "    V = V.reshape(-1, n_occ, n_vir)\n",
    "    # this feature can deal with multiple vectors\n",
    "    sTDA_V = delta_fly (V) + 2*iajb_fly (V) - ijab_fly (V)\n",
    "    sTDA_V = sTDA_V.reshape(-1,n_occ*n_vir)\n",
    "    return sTDA_V\n",
    "\n",
    "n = n_occ*n_vir\n",
    "I = np.eye(n)\n",
    "sTDA_A = sTDA_fly(I)\n",
    "\n",
    "s, u = np.linalg.eigh(sTDA_A)\n",
    "print(s[:4]*27.21138624598853)\n",
    "plt.matshow(sTDA_A)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Davidson(object):\n",
    "    \"\"\" the general frame of Davidson \"\"\"\n",
    "    def setup_D(self):\n",
    "        pass\n",
    "    \n",
    "    def scale(self):\n",
    "        pass\n",
    "    \n",
    "    def get_initial(self):\n",
    "        sort = hdiag.argsort()\n",
    "        self.new_guess = np.zeros((self.A_dim, self.nstates))\n",
    "#         print('initial guess shape', self.new_guess.shape)\n",
    "        for i in range(self.nstates):\n",
    "            self.new_guess[sort[i], i] = 1.0\n",
    "\n",
    "    \n",
    "    # orthonormalization of guess_vectors\n",
    "    def Gram_Schdmit_vec(self, V, vec):\n",
    "        \"\"\"suppose A is orthonormalized\"\"\"\n",
    "        \"\"\"orthonormalize |vec> against each column of V\"\"\"\n",
    "        if V.shape[0] != 0:\n",
    "            vec = vec.reshape(-1,1)\n",
    "            proj_coeff = np.dot(V, vec)\n",
    "            vec = vec - np.dot(V.T, proj_coeff)\n",
    "        return vec\n",
    "\n",
    "    def Gram_Schdmit_fill_holder(self):\n",
    "        nvec = self.new_guess.shape[1]\n",
    "        #  self.new_m will real-time amount of <bra|s in V\n",
    "        \n",
    "        for j in range (nvec):\n",
    "            vec = self.new_guess[:,j]\n",
    "            vec = self.Gram_Schdmit_vec(self.V[:self.new_m,:],vec)   #single orthonormalize\n",
    "            vec = self.Gram_Schdmit_vec(self.V[:self.new_m,:],vec)   #double orthonormalize\n",
    "            norm = np.linalg.norm(vec)\n",
    "            if  norm > 1e-14:\n",
    "                vec = (vec/norm).reshape(1,-1)\n",
    "                self.V[self.new_m,:] = vec\n",
    "                self.new_m += 1\n",
    "     \n",
    "    def matrix_vector(self, X):\n",
    "        return vind(X)\n",
    "\n",
    "    def get_sub_guess(self):\n",
    "        self.s, self.sub_guess = np.linalg.eigh(self.sub_A)\n",
    "        # self.s is eigenvalues\n",
    "        # self.sub_guess is eigenkets\n",
    "\n",
    "    def get_full_guess(self):\n",
    "        self.full_guess = np.dot(self.sub_guess[:,:self.nstates].T, self.V[:self.new_m,:]).T\n",
    "       \n",
    "        # full_guess is |ket>\n",
    "\n",
    "    def get_residual(self):\n",
    "#         self.residual = self.matrix_vector(self.full_guess.T).T - self.full_guess * self.s[:self.nstates]\n",
    "        self.residual = np.dot(self.W[:self.new_m,:].T, self.sub_guess[:,:self.nstates]) - self.full_guess * self.s[:self.nstates]\n",
    "        # residual is |ket>\n",
    "    \n",
    "    def get_sub_B(self):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "    def precondition(self):\n",
    "        t = 1e-14\n",
    "        D = np.repeat(hdiag.reshape(-1,1), len(self.index), axis=1) - self.s[self.index]\n",
    "        D = np.where(abs(D)<t, np.sign(D)*t, D)\n",
    "        # if <t, then return 'np.sign(D)*t', else D (original value)\n",
    "        # force all values not in domain (-t, t)\n",
    "        self.new_guess = self.residual[:,self.index]/D\n",
    "          \n",
    "    def kernel(self, nstates=5, tol=1e-5):\n",
    "        self.max = 30\n",
    "        \n",
    "        self.nstates = nstates\n",
    "        self.tol = tol\n",
    "\n",
    "        self.m = 0\n",
    "        self.new_m = 0\n",
    "\n",
    "        self.A_dim = n_occ * n_vir\n",
    "        # currently, no basis in V\n",
    "\n",
    "        # the first step is to add k basis into V\n",
    "        # namely, the amount of initial guesses\n",
    "        # new_m = min([2*k, k+8, occupied*virtual])\n",
    "\n",
    "        self.V = np.zeros(((self.max+1)*self.nstates, self.A_dim))\n",
    "        self.W = zeros_like(self.V)\n",
    "        \n",
    "        i_start = time.time()\n",
    "        self.setup_D()\n",
    "        self.get_initial()\n",
    "#         print('00, m, new_m', self.m, self.new_m)\n",
    "        \n",
    "        i_end = time.time()\n",
    "#         print(\"icost \", i_end - i_start)\n",
    "        \n",
    "        mv_cost = 0\n",
    "        p_cost = 0\n",
    "        G_cost = 0\n",
    "        o_cost = 0\n",
    "        for ii in range(self.max):\n",
    "#             print(\"ii = \", ii)\n",
    "            G_start = time.time()\n",
    "            self.Gram_Schdmit_fill_holder()\n",
    "            G_end = time.time()\n",
    "            G_cost += G_end - G_start \n",
    "#             print('0 m, new_m', self.m, self.new_m)\n",
    "            mv_start = time.time()\n",
    "            self.W[self.m:self.new_m,:] = self.matrix_vector(self.V[self.m:self.new_m,:])\n",
    "            mv_end = time.time()\n",
    "            mv_cost += mv_end - mv_start\n",
    "#             print(\"1shape of self.new_guess \", self.new_guess.shape)\n",
    "#             print('1 m, new_m', self.m, self.new_m)\n",
    "#             print(\"2shape of self.new_guess \", self.new_guess.shape)\n",
    "            \n",
    "            self.sub_A = np.dot(self.W[:self.new_m,:], self.V[:self.new_m,:].T)\n",
    "            self.get_sub_B()\n",
    "#             print(\"3shape of self.new_guess \", self.new_guess.shape)\n",
    "            self.get_sub_guess()\n",
    "            \n",
    "#             print(\"4shape of self.new_guess \", self.new_guess.shape)\n",
    "            self.get_full_guess()\n",
    "            \n",
    "#             print('5shape of self.full_guess', self.full_guess.shape)\n",
    "            o_start = time.time()\n",
    "            self.get_residual()\n",
    "            o_end = time.time()\n",
    "#             print(\"6shape of self.new_guess \", self.new_guess.shape)\n",
    "            r_norms = np.linalg.norm(self.residual, axis=0).tolist()\n",
    "            print('r norms',r_norms)\n",
    "            \n",
    "            o_cost += o_end - o_start\n",
    "            max_norm = np.max(r_norms)\n",
    "            if max_norm < self.tol:\n",
    "                print ('All guesses converged!')\n",
    "                break\n",
    "            self.index = [r_norms.index(i) for i in r_norms if i > self.tol]\n",
    "            print('self.index', self.index)\n",
    "            p_start = time.time()\n",
    "            self.precondition()\n",
    "            p_end = time.time()\n",
    "            p_cost += p_end - p_start\n",
    "#             print(\"7shape of self.new_guess\", self.new_guess.shape)\n",
    "            self.m = self.new_m\n",
    "        \n",
    "        \n",
    "        print(\"ii = \", ii)\n",
    "#         print(\"G_cost \", G_cost)\n",
    "#         print('mv_cost', mv_cost)\n",
    "#         print(\"o_cost \", o_cost)\n",
    "#         print('p_cost', p_cost)\n",
    "#         print(self.s[:self.nstates]*27.21138624598853)   \n",
    "#         27.211386245988 https://physics.nist.gov/cgi-bin/cuu/Value?hrev|search_for=hartree\n",
    "        if hasattr(self, 's'):\n",
    "            print(self.s[:self.nstates]*27.211386031943245)# this unit converting is much closer!!!\n",
    "            return self.s[:self.nstates], self.full_guess\n",
    "        else:\n",
    "            self.scale()\n",
    "            return self.full_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sTDA_prec(Davidson):\n",
    "\n",
    "    def __init__(self, eigen_la, B):\n",
    "        self.eigen_la = eigen_la\n",
    "            \n",
    "        self.bnorm = np.linalg.norm(B, axis=0, keepdims = True)\n",
    "        #norm of each vectors in B, shape (1,-1)\n",
    "        \n",
    "        self.B = B/self.bnorm\n",
    "    \n",
    "    def setup_D(self):\n",
    "        \n",
    "        N_rows = np.shape(self.B)[0]\n",
    "        self.B = self.B.reshape(N_rows, -1)\n",
    "        N_vectors = np.shape(self.B)[1]\n",
    "        self.tol = 1e-2\n",
    "        \n",
    "        t = 1e-10\n",
    "        D = np.repeat(hdiag.reshape(-1,1), N_vectors, axis=1) - self.eigen_la\n",
    "        D = np.where(abs(D)<t, np.sign(D)*t, D) # <t: returns np.sign(D)*t; else: D\n",
    "        self.inv_D = 1/D\n",
    "        \n",
    "    \n",
    "    def get_initial(self):\n",
    "        self.new_guess = self.B * self.inv_D\n",
    "    \n",
    "    def matrix_vector(self, X):\n",
    "        return sTDA_fly(X)\n",
    "    \n",
    "    def precondition(self):\n",
    "        self.new_guess = self.residual[:,self.index] * self.inv_D[:,self.index]\n",
    "        \n",
    "    def get_sub_B(self):\n",
    "        self.sub_B = np.dot(self.V[:self.new_m, :], self.B)\n",
    "        \n",
    "    def get_sub_guess(self):\n",
    "        # AX - Xeigen_la  = B\n",
    "        N_vectors = len(self.eigen_la)\n",
    "        a, u = np.linalg.eigh(self.sub_A)\n",
    "        ub = np.dot(u.T, self.sub_B)\n",
    "        ux = np.zeros_like(self.sub_B)\n",
    "        for k in range(N_vectors):\n",
    "            ux[:, k] = ub[:, k]/(a - self.eigen_la[k])\n",
    "        self.sub_guess = np.dot(u, ux)\n",
    "        \n",
    "    def get_residual(self):\n",
    "        self.residual = np.dot(self.W[:self.new_m, :].T, self.sub_guess) - self.full_guess * self.eigen_la - self.B\n",
    "        \n",
    "        \n",
    "    def scale(self):\n",
    "        self.full_guess = self.full_guess * self.bnorm\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Davidson_p_sTDA(Davidson):\n",
    "    \n",
    "    def precondition(self):\n",
    "        self.new_guess = sTDA_prec(self.s[self.index], self.residual[:,self.index]).kernel()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r norms [0.2541255441675327, 0.0949599082334803, 0.12845335921232787]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.030759293560356112, 0.0018422298262628027, 0.0024232481390696033]\n",
      "self.index [0]\n",
      "r norms [0.005847153973591403, 0.001954482731935165, 0.007383573489466294]\n",
      "All guesses converged!\n",
      "ii =  2\n"
     ]
    }
   ],
   "source": [
    "result = sTDA_prec([6.46714168,8.18163055,8.3832315],np.random.rand(351,3)).kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r norms [0.06253949269151338, 0.04935058759405762, 0.07799695254034207, 0.04462766638529374, 0.09431800496070981]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.3094067991886459, 0.3547109789272382, 0.4266057429398744, 0.28737323673572157, 0.40509971108224324]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.12804812798731113, 0.329201308193924, 0.4979524442193667, 0.9592220543758737, 15.676062619161677]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [1.0104913217279785, 0.34919248004911846, 4.164706323555166, 59.958921361193546, 1.1838082813312667]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.08250174513509477, 0.4287631863767634, 0.5986089880208001, 1.2114180494931395, 1.8933850142652955]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.04708635079437153, 0.09867655764336684, 0.6752963495975502, 1.6767712020612784, 0.9021771291240509]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.02194272676996452, 11.392854026498686, 0.7030534362259451, 26.366309390305336, 0.6930281792582917]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.00775703569757169, 0.0855804171766381, 0.42277734311483534, 1.7759136663739463, 0.6413316290523162]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0029619565583686195, 0.03363723611937091, 0.2034975761417515, 0.9812084081712779, 0.4768626713566407]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0016937312674930134, 0.004417387463923689, 0.0993723358537019, 0.14916133338478807, 0.4708603144440775]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.0013671506720923964, 0.0008079025468903478, 0.03299968156357715, 0.03863475465268728, 0.2688008917879672]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.0014564068559320357, 0.00026612715285077523, 0.009409468590107902, 0.009010565069230715, 0.1418003505201774]\n",
      "self.index [4]\n",
      "r norms [0.0014564074192560351, 0.0002661245646336286, 0.00539863216921527, 0.009010602264615175, 0.0918137719017217]\n",
      "self.index [4]\n",
      "r norms [0.0014564072044698777, 0.00026610744557597734, 0.0034626410101984977, 0.009010631002234268, 0.03914326521999379]\n",
      "self.index [4]\n",
      "r norms [0.0014563731734375351, 0.00026610211636548083, 0.0032732224089717407, 0.009010535997692875, 0.009895374308129801]\n",
      "All guesses converged!\n",
      "ii =  13\n",
      "r norms [0.00574987376836125, 0.009042654354954958, 0.07021848109340749, 0.048658082445952384, 0.07196753858527945]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.22587270332726475, 0.2835550724317194, 0.27954360689035007, 0.2367426492994668, 0.26631036520724277]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0904776516617915, 0.17228490612530759, 0.22621315623284824, 0.30224789566929305, 0.3555806690496747]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.17714048847843936, 0.4727883975059752, 0.24205215409515146, 0.5764298162803826, 1.0835828116111126]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.024496032015067767, 0.041562735487444574, 0.478410124070433, 0.8100974308574628, 0.18826561246456622]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.022191713428940864, 0.01559179828215979, 1.6150643349068046, 1.1963674105146616, 0.23359892946811447]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.008836033107429099, 0.02841890169971251, 0.332486624426228, 6.009989294732029, 0.4658608714113995]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0034500798061688205, 0.00635760164491347, 0.41759693465651054, 0.6143826274735062, 0.2912671584366747]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.003831262840812831, 0.006051393903199204, 0.2309624145612921, 0.13679672623425226, 0.0881959099845216]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.002896976216628772, 0.006267121231430493, 0.09112001439464386, 0.03379514752701211, 0.04671506595501983]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.0027933338703948793, 0.005241199615304981, 0.03139760090992598, 0.00845272157604009, 0.03297804559879955]\n",
      "self.index [2, 4]\n",
      "r norms [0.0027938000668001465, 0.005241882522392697, 0.005871227841577637, 0.00844375954481612, 0.012990296227156386]\n",
      "self.index [4]\n",
      "r norms [0.0027897281284347103, 0.005237192440522784, 0.006108343327785973, 0.008428695348639659, 0.003458535998111294]\n",
      "All guesses converged!\n",
      "ii =  11\n",
      "r norms [0.0005966606498860917, 0.01974511265140613, 0.0009893658086968695, 0.014621434494579883, 0.020525368308820773]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.19074441296915473, 0.3121869507336722, 0.25997081523397053, 0.6164064743393689, 0.3891332096751759]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.03928021167972135, 0.13498973560310942, 0.1442824198296049, 0.8243483868469502, 0.4576847234996565]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0171586735135189, 0.3513621661202336, 0.7343218217392701, 0.37506063106817933, 1.9835873350669162]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.019689516535566522, 0.048242365507352274, 0.10740847592073188, 0.4233732015643798, 0.3617982229139483]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.009587320873698643, 0.025191716483279364, 0.02171626414464615, 0.08603995570088098, 1.4514737183920838]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.006686196609419283, 0.03797902182600766, 0.03078649486220999, 0.13987638556480964, 0.13480051910622012]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.005404422513192688, 0.09651522310088054, 1.3520747620402014, 0.05011043712110561, 0.05613798111652764]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0022821538269884615, 0.06357670504206372, 0.0580482679872889, 0.03422373682961118, 0.12317361919373421]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0023558941617669465, 0.019542052483601507, 0.03092111898813452, 0.07973866828182131, 0.032527595017431986]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.0020104315053760704, 0.006591465973250568, 0.01038777544590952, 0.3383451499553138, 0.016738897040880586]\n",
      "self.index [2, 3, 4]\n",
      "r norms [0.0012107608461482998, 0.002192292686982421, 0.0011581832628482593, 0.14183709252102358, 0.014083593090640258]\n",
      "self.index [3, 4]\n",
      "r norms [0.0011692744465621912, 0.002425173479382027, 0.000533444002178971, 0.07893792013253792, 0.014935821656727456]\n",
      "self.index [3, 4]\n",
      "r norms [0.0011605539505977432, 0.0022643868641058712, 0.0002623188184152627, 0.03704471535455676, 0.007157974972645997]\n",
      "self.index [3]\n",
      "r norms [0.0011938278988689653, 0.0021889744951059512, 0.00026825611911371203, 0.0151702096259585, 0.0024914657517824653]\n",
      "self.index [3]\n",
      "r norms [0.001106009685943373, 0.0020176352518329896, 0.00019995356899032258, 0.003866726839642619, 0.001076656500168203]\n",
      "All guesses converged!\n",
      "ii =  14\n",
      "r norms [6.652796549357145e-05, 0.005625514823518549, 9.385924248250296e-05, 0.003879475335083406, 0.006518953341565689]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.1698349035071876, 0.3306546831783121, 0.30707042147238695, 0.15665808366760556, 0.390835795961609]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.05145545306445944, 0.1781550045297674, 0.08127950863004872, 0.08200214674415873, 0.2877484214216234]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.34609099718679337, 0.16873073911980518, 0.1284834793232549, 0.15366383217119126, 0.9871061911226151]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0397298245173492, 0.29460307969473964, 0.10136290840745447, 0.04921445693639471, 0.29832184423381175]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.01971959592594889, 3.9873636462837903, 0.10783156761278104, 0.07901816180289357, 0.18676076414593398]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.011705318003195103, 0.43368540009725576, 4.317271820399939, 0.04315455189487978, 0.11862940505954196]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.002558721217149542, 0.1243359377520404, 0.04280804037022198, 0.012702783736775141, 0.10045718846050276]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.001620827842814978, 0.18386480232550867, 0.01021927298693652, 0.05340156224846353, 0.24768847690474913]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.001342238122400086, 0.09585686268459377, 0.003152635847796415, 0.016621794606773283, 0.0592465379684476]\n",
      "self.index [1, 3, 4]\n",
      "r norms [0.001206281385470055, 0.0271056122096402, 0.001922151833568859, 0.01121304226787887, 0.019233548410381916]\n",
      "self.index [1, 3, 4]\n",
      "r norms [0.0010835581098893998, 0.009123901889065393, 0.001441205812634719, 0.014610521391352028, 0.014188962638726606]\n",
      "self.index [3, 4]\n",
      "r norms [0.0010657507019816677, 0.002796558178765343, 0.001500013079297311, 0.009299078223702972, 0.009172584321004122]\n",
      "All guesses converged!\n",
      "ii =  11\n",
      "r norms [3.901674807749184e-06, 0.0029096599029470593, 1.006992036455692e-05, 0.0003845096280538638, 0.0015386531414505976]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [0.2173222030886979, 0.2517619560741112, 0.4339793237713083, 0.26444454233622566]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.14403679480393342, 0.0835414835899244, 0.16264536549159408, 0.24394531820563733]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.6049448565460424, 0.15307448057497755, 0.21737642918613959, 0.4226481246201646]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [5.11437541572193, 0.18676517453147642, 0.06242823088176852, 0.11864082057238547]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.2053750636024381, 0.05126494992190964, 0.08295711451344144, 0.08569536504522064]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.08034643707239755, 0.31310081887301294, 0.09432661400001428, 0.06538878994322855]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.08271647057698381, 0.12400257049091495, 0.028000692321241142, 0.09625527226295655]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.0633033852451011, 0.04249505911316169, 0.0163704147510798, 0.05191271175204453]\n",
      "self.index [0, 1, 2, 3]\n",
      "r norms [0.04595324471678937, 0.015117351640410172, 0.006292980693831954, 0.0201614175470661]\n",
      "self.index [0, 1, 3]\n",
      "r norms [0.014001540698834717, 0.0050698952459403, 0.008350583810130187, 0.007313088488640193]\n",
      "self.index [0]\n",
      "r norms [0.004812024951796403, 0.004729808831158436, 0.00836196050325619, 0.005602909496758183]\n",
      "All guesses converged!\n",
      "ii =  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r norms [3.884443967302033e-06, 0.0013473974980125502, 1.267023552414092e-06, 4.919763872387177e-05, 0.00033177295326926564]\n",
      "self.index [1, 3, 4]\n",
      "r norms [0.2755325405421998, 0.27560773679709283, 0.32941409348635836]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.15801365339426465, 0.10626285317183339, 0.26499402609773176]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.09232054578946368, 0.7083091745767016, 0.3478338624425463]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.22138984674992443, 0.04480394809142532, 0.3220715643672663]\n",
      "self.index [0, 1, 2]\n",
      "r norms [1.8021447886612945, 0.09884105880921076, 0.12922363155728825]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.19433080513308024, 0.09727018536551967, 0.12136105748998652]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.17976380720924764, 0.03907004446134458, 0.10711179806384931]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.42553825711109383, 0.04029509543627668, 0.031884102889438694]\n",
      "self.index [0, 1, 2]\n",
      "r norms [0.06909696600089424, 0.009080845017384733, 0.010528210755271628]\n",
      "self.index [0, 2]\n",
      "r norms [0.04533156631089361, 0.009462745710829392, 0.007660841386809742]\n",
      "self.index [0]\n",
      "r norms [0.014588024171519848, 0.008415956571601864, 0.00609167779466461]\n",
      "self.index [0]\n",
      "r norms [0.003102559717392847, 0.008432967263829784, 0.00626874965618728]\n",
      "All guesses converged!\n",
      "ii =  11\n",
      "r norms [3.881960770691236e-06, 0.00026791780495243127, 9.385822983266162e-07, 6.121260903399284e-06, 7.559532343783169e-05]\n",
      "self.index [1, 4]\n",
      "r norms [0.20092943049936826, 0.2419682583813834]\n",
      "self.index [0, 1]\n",
      "r norms [0.1000342322905573, 0.194241082593463]\n",
      "self.index [0, 1]\n",
      "r norms [0.0860978468512084, 0.3009336224913774]\n",
      "self.index [0, 1]\n",
      "r norms [0.14356978911404802, 0.1803569687563963]\n",
      "self.index [0, 1]\n",
      "r norms [0.09475953836803958, 0.1475569574496046]\n",
      "self.index [0, 1]\n",
      "r norms [0.4497416408302946, 0.11303623242038412]\n",
      "self.index [0, 1]\n",
      "r norms [0.07312303718169168, 0.057681128808163916]\n",
      "self.index [0, 1]\n",
      "r norms [0.8915616277322425, 0.11968396347293643]\n",
      "self.index [0, 1]\n",
      "r norms [0.061782690114898904, 0.06733141756484165]\n",
      "self.index [0, 1]\n",
      "r norms [0.024041664723443813, 0.04946938219263028]\n",
      "self.index [0, 1]\n",
      "r norms [0.008164343406084369, 0.016971830682204994]\n",
      "self.index [1]\n",
      "r norms [0.00834617936654629, 0.008629455500594742]\n",
      "All guesses converged!\n",
      "ii =  11\n",
      "r norms [3.881860629705025e-06, 2.801392126157316e-05, 9.376848643654449e-07, 6.099196100312059e-06, 1.0226442576696325e-05]\n",
      "self.index [1, 4]\n",
      "r norms [0.21781321537723825, 0.33170143837562366]\n",
      "self.index [0, 1]\n",
      "r norms [0.0665360716686563, 0.19111897386264]\n",
      "self.index [0, 1]\n",
      "r norms [0.021657980595081346, 0.07722724049163529]\n",
      "self.index [0, 1]\n",
      "r norms [0.11000683514808521, 0.3826195883179765]\n",
      "self.index [0, 1]\n",
      "r norms [0.0213686342671777, 0.07113964841631641]\n",
      "self.index [0, 1]\n",
      "r norms [0.02306485521806089, 1.5504706281501703]\n",
      "self.index [0, 1]\n",
      "r norms [0.14542696918224915, 0.05151449933873697]\n",
      "self.index [0, 1]\n",
      "r norms [0.05912913959948818, 0.054347823208978054]\n",
      "self.index [0, 1]\n",
      "r norms [0.38101561713754456, 0.04203963119903286]\n",
      "self.index [0, 1]\n",
      "r norms [0.021555814441644783, 0.01037807393548934]\n",
      "self.index [0, 1]\n",
      "r norms [0.00803363272415723, 0.008008189952248548]\n",
      "All guesses converged!\n",
      "ii =  10\n",
      "r norms [3.881865116785975e-06, 2.5510204209937363e-06, 9.37288887205372e-07, 6.098165943895226e-06, 1.934393171204432e-06]\n",
      "All guesses converged!\n",
      "ii =  8\n",
      "[ 7.60448706  9.60736876  9.65608887 10.54993156 10.84667365]\n",
      "time = 3.5329151153564453\n"
     ]
    }
   ],
   "source": [
    "p_sTDA = Davidson_p_sTDA()\n",
    "\n",
    "start = time.time()\n",
    "p_sTDA.kernel()\n",
    "end = time.time()\n",
    "print('time =', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r norms [0.06253949269151338, 0.04935058759405762, 0.07799695254034207, 0.04462766638529374, 0.09431800496070981]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.020287838902830424, 0.01501546438195711, 0.03291607646520453, 0.01224670075298954, 0.02491420710309575]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0031948562589936024, 0.015520240917591363, 0.006190099906518566, 0.01581627179086854, 0.009899978693477704]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0006415302135526909, 0.009008374952898173, 0.0017496078001537447, 0.008123413242139405, 0.005749972954092483]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [0.0001764773799831265, 0.00442714521810677, 0.00041041651982414145, 0.004073283161484904, 0.0020313807927332247]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [3.600175475628768e-05, 0.0010236214550330075, 9.63793160225989e-05, 0.0015670828573292768, 0.0009518424123647994]\n",
      "self.index [0, 1, 2, 3, 4]\n",
      "r norms [6.245470375743961e-06, 0.0003771139067481623, 1.5204650682092778e-05, 0.0005130865182193305, 0.00032938111329585795]\n",
      "self.index [1, 2, 3, 4]\n",
      "r norms [3.632591845140702e-06, 9.606168026769942e-05, 2.847989936670811e-06, 0.00010253712038951919, 0.00010857009746968088]\n",
      "self.index [1, 3, 4]\n",
      "r norms [3.6383015719585553e-06, 2.22061500917344e-05, 2.1971569794125303e-06, 3.6134165577183105e-05, 3.5644891198877505e-05]\n",
      "self.index [1, 3, 4]\n",
      "r norms [3.6384428732523474e-06, 9.72455188580381e-06, 1.9199814719857194e-06, 9.279880019911886e-06, 1.1202129638627784e-05]\n",
      "self.index [4]\n",
      "r norms [3.6384833828814534e-06, 9.757583980402496e-06, 1.9200277435250043e-06, 9.280738717265902e-06, 2.7964844922207596e-06]\n",
      "All guesses converged!\n",
      "ii =  10\n",
      "[ 7.60448706  9.60736876  9.65608887 10.54993156 10.84667365]\n",
      "time = 4.470609188079834\n"
     ]
    }
   ],
   "source": [
    "a = Davidson()\n",
    "a.nstates = 5\n",
    "b = time.time()\n",
    "a.kernel()\n",
    "e = time.time()\n",
    "print('time =', e-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = time.time()\n",
    "# td.nstates = 5\n",
    "# td.conv_tol = 1e-10\n",
    "# td.verbose = 4\n",
    "# td.kernel()\n",
    "# e = time.time()\n",
    "# print('time =', e-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Davidson_sTDA_mv(Davidson):\n",
    "    def matrix_vector(self, X):\n",
    "        return sTDA_fly(X)\n",
    "\n",
    "Davidson_sTDA_mv = Davidson_sTDA_mv()   \n",
    "Davidson_sTDA_mv.kernel()\n",
    "\n",
    "# #or:\n",
    "# Davidson0 = Davidson()\n",
    "# Davidson0.matrix_vector = sTDA_fly\n",
    "# Davidson0.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Davidson_i_sTDA(Davidson):\n",
    "    def initial(self):\n",
    "        eigenvalues, self.new_guess = Davidson_sTDA_mv.kernel()\n",
    "Davidson_isip = Davidson_i_sTDA()\n",
    "Davidson_isip.kernel()\n",
    "# standard: [ 7.60448706  9.60736875  9.65608887 10.54993156 10.84667365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def A_diag_preconditioner (residual, sub_eigenvalue):\n",
    "#     # preconditioners for each corresponding residual\n",
    "#     k = np.shape(residual)[1]\n",
    "#     zz = 1e-14\n",
    "#     D = np.zeros((n, k))\n",
    "#     for i in range (0, k):\n",
    "#         D[:,i] = hdiag - sub_eigenvalue[i]\n",
    "#         D[:,i][(D[:,i]<zz)&(D[:,i]>=0)] = zz\n",
    "#         D[:,i][(D[:,i]>-zz)&(D[:,i]<0)] = -zz\n",
    "#     new_guess = residual/D\n",
    "#     return new_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# # original Davidson, to solve eigenvalues and eigenkets of sTDA_A matrix\n",
    "# def Davidson (k):\n",
    "#     tol = 1e-5 # Convergence tolerance\n",
    "#     n = occupied*virtual # size of sTDA_A matrix\n",
    "#     max = 30\n",
    "#     #################################################\n",
    "#     # generate initial guess\n",
    "#     # m is size of subspace\n",
    "#     m = min([2*k, k+8, occupied*virtual])\n",
    "#     # a container to hold guess vectors\n",
    "#     V = np.zeros((n, 30*k))\n",
    "#     W = np.zeros((n, 30*k))\n",
    "    \n",
    "#     # positions of hdiag with lowest values set as 1\n",
    "#     # hdiag is non-interactiong A matrix\n",
    "#     sort = hdiag.argsort()\n",
    "#     for j in range(0,m):\n",
    "#         V[int(np.argwhere(sort == j)), j] = 1\n",
    "\n",
    "#     W[:, :m] = sTDA_fly(V[:, :m])\n",
    "#     #generate initial guess and put in holders V and W\n",
    "    \n",
    "#     ###########################################################################################\n",
    "#     for i in range(0, max):\n",
    "#         # sub_A is subspace A matrix\n",
    "#         sub_A = np.dot(V[:,:m].T, W[:,:m])\n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A)\n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "#         #sub_eigenvalue[:k] are smallest k eigenvalues\n",
    "#         residual = np.dot(W[:,:m], sub_eigenket[:,:k]) - np.dot(V[:,:m], sub_eigenket[:,:k] * sub_eigenvalue[:k])\n",
    "# #         print ('shape of residual', np.shape(residual))\n",
    "#         Norms_of_r = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "\n",
    "#         # largest residaul norm\n",
    "#         max_norm = np.max(Norms_of_r)\n",
    "\n",
    "#         if max_norm < tol:\n",
    "#             break\n",
    "\n",
    "#         # index for unconverged residuals\n",
    "#         index = [i for i in range(np.shape(Norms_of_r)[1]) if Norms_of_r[0,i] > tol]\n",
    "     \n",
    "#         ########################################\n",
    "#         # preconditioning step\n",
    "#         # only generate new guess from unconverged residuals\n",
    "#         new_guess = A_diag_preconditioner (residual[:,index], sub_eigenvalue[:k][index])\n",
    "\n",
    "#         # orthonormalize the new guesses against old guesses\n",
    "#         # and put into V holder\n",
    "#         V, new_m = Gram_Schdmit_fill_holder (V, m, new_guess)\n",
    "#         W[:, m:new_m] = sTDA_fly (V[:, m:new_m])\n",
    "#         m = new_m\n",
    "#     ###########################################################################################\n",
    "#     full_guess = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "#     print ('Iteration steps =', i+1)\n",
    "#     print ('Final subspace size = ', np.shape(sub_A))\n",
    "#     # print ('Davidson time:', round(end-start,4))\n",
    "\n",
    "#     return (sub_eigenvalue[:k]*27.21138624598853, full_guess)\n",
    "# ###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies, kets = Davidson(4)\n",
    "# print (energies)\n",
    "\n",
    "# [12.2388045  13.59944497 13.79151538 15.04073066 15.10727607 15.24503727\n",
    "#  16.45336705 16.51809479 16.8506097  17.3015488 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def orthonormalize (v1, v2):\n",
    "# #     v1 = v1/np.linalg.norm(v1)\n",
    "#     v2 = v2 - (np.dot(v1, v2) / np.dot(v1, v1)) * v1\n",
    "# #     v2 = v2 - np.dot(v1, v2) * v1\n",
    "#     v2 = v2/np.linalg.norm(v2)\n",
    "#     return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # suppose a has N columns\n",
    "# #a[:, :n] means the first n columns\n",
    "# #a[:, n:] means \"except\" the first n columns\n",
    "\n",
    "# #a[:, -n:] means the last n columns\n",
    "# #a[:, :-n] means the firts (N-n) columns, or \"except\" the last n columns\n",
    "\n",
    "# #a[:, n:m] measn from index(n) column to index(m-1) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Gram_Schdmit_append (A, B):\n",
    "#     # A_I*P, B_I*Q\n",
    "#     # suppose A is already orthonormalized\n",
    "#     # append B to A, and orthonormalize matrix B against A, \n",
    "    \n",
    "#     A_vectors = np.shape(A)[1]\n",
    "#     B_vectors = np.shape(B)[1]\n",
    "    \n",
    "#     C = np.append (A, B, axis=1)\n",
    "    \n",
    "#     for j in range (0, B_vectors):\n",
    "#         bvec = B[:,j]\n",
    "#         bvec = Gram_Schdmit_bvec (C[:, :A_vectors + j], B[:,j])\n",
    "#         C[:, A_vectors + j] = bvec/np.linalg.norm(bvec)\n",
    "#     return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Gram_Schdmit_against (A, B):\n",
    "#     # suppose A is already orthonormalized\n",
    "#     # orthonormalize vectors in B against A, as well as B it self\n",
    "  \n",
    "#     A_vectors = np.shape(A)[1]\n",
    "#     B_vectors = np.shape(B)[1]\n",
    "\n",
    "#     for j in range (0, B_vectors):\n",
    "#         bvec = B[:,j] \n",
    "#         bvec = Gram_Schdmit_bvec (A, bvec)\n",
    "#         if np.linalg.norm(bvec) < 1e-7:\n",
    "#             index.append(j)\n",
    "#         else:\n",
    "#             B[:,j] = bvec/np.linalg.norm(bvec)\n",
    "# #     print (type(index)) #list\n",
    "# #     print (index)\n",
    "\n",
    "#     B = np.delete(B, index, axis=1)\n",
    "        \n",
    "#     B = Gram_Schdmit (B)\n",
    "# #     print (np.shape(B))\n",
    "#     return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iajb_v = np.einsum('Aia, Bjb, AB, jbm -> iam', q_tensor_ia, q_tensor_ia, GammaK, V)\n",
    "\n",
    "# # ijab_v = np.einsum('Aij, Bab, AB, jbm -> iam', q_tensor_ij, q_tensor_ab, GammaJ, V)\n",
    "\n",
    "\n",
    "# def iajb_fly (V):\n",
    "#     V = V.reshape(n_occ, n_vir, -1)\n",
    "#     Q_K_V = np.einsum('Ajb, jbm -> Am', Q_K, V)\n",
    "#     iajb_V = np.einsum('Aia, Am -> iam', q_tensor_ia, Q_K_V).reshape(n_occ*n_vir, -1)\n",
    "# #     print('iajb done')\n",
    "#     return iajb_V\n",
    "\n",
    "# def ijab_fly (V):\n",
    "#     V = V.reshape(n_occ, n_vir, -1)\n",
    "# #     ijab_v = np.einsum('Aij, Aab, jbm -> iam', q_tensor_ij, Q_J,  V)\n",
    "\n",
    "#     Aij_V = np.einsum('Aij, jbm -> Aibm', q_tensor_ij, V)\n",
    "#     ijab_V = np.einsum('Aab, Aibm -> iam', Q_J, Aij_V).reshape(n_occ*n_vir, -1)\n",
    "\n",
    "# #     print ('ijab done')\n",
    "# #     Aab_V = np.einsum('Aab, jbm -> jAam', Q_J, V)\n",
    "# #     ijab_V = np.einsum('Aij, jAam -> iam', q_tensor_ij, Aab_V).reshape(n_occ*n_vir, -1)\n",
    "#     return ijab_V\n",
    "\n",
    "# delta_diag_A = hdiag.reshape(n_occ, n_vir)\n",
    "\n",
    "\n",
    "# def delta_fly (V):\n",
    "#     V = V.reshape(n_occ, n_vir, -1)\n",
    "# #     print ('Shape of V = ', np.shape(V))\n",
    "#     #delta_v = np.einsum('ij,ab,ia,jb -> ia',delta_ij,delta_ab,delta_diag_A, v)\n",
    "#     delta_v = np.einsum('ia,iam -> iam', delta_diag_A, V).reshape(n_occ*n_vir, -1)\n",
    "#     return delta_v\n",
    "\n",
    "# def sTDA_fly (V):\n",
    "#     V = V.reshape(n_occ*n_vir,-1)\n",
    "#     # -1 means shape of first dimension is not asigned, but can be inferred with the rest dimension\n",
    "#     # this feature can deal with multiple vectors\n",
    "#     sTDA_V =  delta_fly (V) + 2*iajb_fly (V) - ijab_fly (V)\n",
    "# #     sTDA_V = sTDA_V.reshape(n_occ*n_vir, -1)\n",
    "# #     print (np.shape(sTDA_v))\n",
    "#     return sTDA_V\n",
    "\n",
    "# n = occupied * virtual\n",
    "# I = np.eye(n)\n",
    "\n",
    "# start = time.time()\n",
    "# sTDA_B = sTDA_fly (I)\n",
    "# end = time.time()  \n",
    "\n",
    "\n",
    "\n",
    "# s,k = np.linalg.eigh(sTDA_B)\n",
    "# print (s[:10]*27.21138624598853)\n",
    "\n",
    "\n",
    "# plt.matshow(sTDA_B)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_orthonormal (A):\n",
    "#     n = np.shape(A)[1]\n",
    "#     B = np.dot (A.T, A)\n",
    "#     c = np.linalg.norm(B - np.eye(n))\n",
    "#     return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.random.random ((600,120))\n",
    "# A = Gram_Schdmit (a)\n",
    "\n",
    "# b = np.random.random ((600,140))\n",
    "# x = np.random.random ((600,140))\n",
    "# z = np.random.random ((600,14))\n",
    "\n",
    "# # dab = np.append (a,b, axis=1)\n",
    "# # dabx = np.append (dab, x, axis=1)\n",
    "# # dabxz = np.append (dabx, z, axis=1)\n",
    "\n",
    "# # cab = Gram_Schdmit_append (A, b)\n",
    "# # cabx = Gram_Schdmit_append (cab, x)\n",
    "# # cabxz = Gram_Schdmit_append (cabx, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Gram_Schdmit_bvec (A, bvec):\n",
    "#     # suppose A is orthonormalized\n",
    "#     projections_coeff = np.dot(A.T, bvec)\n",
    "#     bvec = bvec - np.dot(A, projections_coeff) \n",
    "# #     count = np.shape(A)[1]\n",
    "# #     for i in range (0, count):\n",
    "# #         bvec = bvec - np.dot(A[:,i], bvec) * A[:,i]\n",
    "#     return bvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Gram_Schdmit (A):\n",
    "#     # A matrix has J columns, orthonormalize each column\n",
    "#     # unqualified vectors will be removed\n",
    "    \n",
    "#     N_rows = np.shape(A)[0]\n",
    "#     N_vectors = np.shape(A)[1]\n",
    "#     A = A/np.linalg.norm(A, axis=0, keepdims = True)\n",
    "    \n",
    "#     B = np.zeros((N_rows,N_vectors))\n",
    "# #     B[:,0] = A[:,0]\n",
    "# #     for p in range (0, J - 1):\n",
    "# #         for q in range (p + 1, J):\n",
    "# #             A[:, q] = orthonormalize(A[:, p], A[:, q])\n",
    "#     count = 0\n",
    "#     for j in range (0, N_vectors):\n",
    "#         print ('shape of B[:, :count] = ', np.shape(B[:, :count]))\n",
    "#         bvec = Gram_Schdmit_bvec (B[:, :count], A[:, j])\n",
    "#         norm = np.linalg.norm(bvec)\n",
    "#         if norm > 1e-14:\n",
    "#             B[:, count]  = bvec/np.linalg.norm(bvec)\n",
    "#             count +=1  \n",
    "#     print ('shape of B[:, :count] = ', np.shape(B[:, :count]))\n",
    "#     return B[:, :count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Gram_Schdmit_fill_holder (V, count, vecs):\n",
    "#     # V, W are holders \n",
    "#     # count is the amount of vectors that already sit in the holder\n",
    "    \n",
    "#     vecs = Gram_Schdmit(vecs)\n",
    "    \n",
    "#     nvec = np.shape(vecs)[1]\n",
    "#     # amount of new vectors intended to fill in\n",
    "    \n",
    "#     i = count\n",
    "#     # i will be final amount of vectors in V\n",
    "    \n",
    "#     for j in range (0, nvec):\n",
    "#         vec = vecs[:, j]\n",
    "#         vec = Gram_Schdmit_bvec(V[:, :i], vec)\n",
    "#         vec = Gram_Schdmit_bvec(V[:, :count], vec)\n",
    "# #         print ('shape of V[:, i:]', np.shape(V[:, :i]))\n",
    "#         norm = np.linalg.norm(vec)\n",
    "# #         print ('norm =', norm)\n",
    "#         if  norm > 1e-14:\n",
    "#             vec = vec/norm\n",
    "#             V[:, i] = vec\n",
    "# #             print (np.shape(vec))\n",
    "#             i += 1\n",
    "# #             print ('i =', i)\n",
    "# #             print ('count =', count)\n",
    "\n",
    "    \n",
    "\n",
    "#     new_count = i\n",
    "# #     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "# #     print ('norms of W =', np.linalg.norm(W, axis=0, keepdims = True))\n",
    "#     return V, new_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros ((351,50))\n",
    "# b = np.zeros ((351,50))\n",
    "# x = np.random.random ((351, 12))\n",
    "# y = Gram_Schdmit(x)\n",
    "# print (np.shape (y))\n",
    "# print (check_orthonormal(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b, c = Gram_Schdmit_fill_holder (a, b, 0, x)\n",
    "# print ('final count =', c)\n",
    "# print ('check_orthonormal a = ', check_orthonormal(a[:, :c]))\n",
    "# # print (np.linalg.norm(a[:, :c] - x))\n",
    "# print ('norms of a =', np.linalg.norm(a, axis=0, keepdims = True))\n",
    "# # print (np.dot (a[:,0],a[:,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_AX_Xla_B (sub_A, eigen_lambda, sub_B):\n",
    "    m = np.shape(sub_A)[0]\n",
    "    I = np.eye(m)\n",
    "    N_vectors = len(eigen_lambda)\n",
    "    X = np.zeros((m, N_vectors))\n",
    "    for i in range (0, N_vectors):\n",
    "        X[:, i] = np.linalg.solve (sub_A - eigen_lambda[i]*I, sub_B[:,i])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "print (type(data_dict))\n",
    "data_dict['John'] = {}\n",
    "data_dict['John']['age'] = '24'\n",
    "data_dict['John']['weight'] = '120'\n",
    "\n",
    "data_dict['Tom'] = {}\n",
    "data_dict['Tom']['age'] = '32'\n",
    "data_dict['Tom']['weight'] = '130'\n",
    "# data_dict['mingzi'] = 'john'\n",
    "# print (data_dict['mingzi'])\n",
    "print (data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "print(yaml.dump({ \"list\": [ { \"foo\" : \"bar1\"}, {\"foo\" : \"bar2\"} ] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def on_the_fly_sTDA_preconditioner (B, eigen_lambda, Y=0): \n",
    "#     N_vectors = np.shape(B)[1]\n",
    "#     Lambda = np.diag(eigen_lambda)\n",
    "# #     print ('shape of Lambda',np.shape(Lambda))\n",
    "#     # (sTDA_A - eigen_lambda*I)^-1 B = X \n",
    "#     # AX - X\\lambda = B\n",
    "#     # columns of B are the vectors to be preconditioned, \n",
    "    \n",
    "#     N_rows = np.shape(B)[0]\n",
    "#     B = B.reshape(N_rows, -1)\n",
    "#     N_vectors = np.shape(B)[1]\n",
    "# #     print ('n_residuals: ', N_vectors)\n",
    "#     #number of vectors to be preconditioned\n",
    "#     bnorm = np.linalg.norm(B, axis=0, keepdims = True)\n",
    "#     #norm of each vectors in B, shape (1,-1)\n",
    "#     B = B/bnorm\n",
    "# #     print ('shape of B=', np.shape(B))\n",
    "#     start = time.time()\n",
    "#     tol = 1e-5     # Convergence tolerance\n",
    "#     max = int(N_rows/N_vectors)   # Maximum number of iterations  \n",
    "    \n",
    "#     V = np.zeros((N_rows, N_rows))\n",
    "#     W = np.zeros((N_rows, N_rows))\n",
    "#     count = 0\n",
    "# #     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "#     # now V and W are empty holders, 0 vectors\n",
    "#     # W = sTDA_fly(V)\n",
    "#     # count is the amount of vectors that already sit in the holder\n",
    "#     # at the end of each iteration, V and W will be filled/updated with new guess vectors\n",
    "    \n",
    "#     ###########################################\n",
    "#     #initial guess: (diag(A) - \\lambda)^-1 B.\n",
    "#     diag = delta_diag_A.flatten()\n",
    "# #     # delta_diag_A.flatten() is (\\spsilon_a-\\spsilon_i)\n",
    "\n",
    "#     zz = 1e-8\n",
    "#     D = np.zeros((N_rows, N_vectors))\n",
    "#     for i in range (0, N_vectors):\n",
    "#         D[:,i] = diag - eigen_lambda[i]\n",
    "#         D[:,i][(D[:,i]<zz)&(D[:,i]>=0)] = zz\n",
    "#         D[:,i][(D[:,i]>-zz)&(D[:,i]<0)] = -zz\n",
    "\n",
    "#     #D is preconditioner for each state \n",
    "# #     print ('shape of D =', np.shape(D))\n",
    "    \n",
    "#     init = B/D\n",
    "# #     print ('check init0', check_orthonormal(init))\n",
    "   \n",
    "# #     print ('norm of init = ', np.linalg.norm (init))\n",
    "# #     print ('check init1', check_orthonormal(init))\n",
    "# #     print ('shape of init =', np.shape(init))\n",
    "# #     print ('check V0', check_orthonormal(V))\n",
    "#     ###########################################\n",
    "#     init = Gram_Schdmit(init)\n",
    "#     print ('shape of init =', np.shape(init))\n",
    "#     new_count = np.shape(init)[1]\n",
    "#     V[:, :new_count] = init\n",
    "# #     V, new_count = Gram_Schdmit_fill_holder (V, count, init)\n",
    "#     W[:, :new_count] = sTDA_fly(V[:, :new_count])\n",
    "#     count = new_count\n",
    "#     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "#     print ('check V0', check_orthonormal(V[:,:count]))\n",
    "\n",
    "#     print ('count = ',count)\n",
    "#     # initial guess settled \n",
    "\n",
    "#     ####################################################################################\n",
    "#     for i in range (0, max):\n",
    "# #         print ('Iteration =', i)\n",
    "#         sub_B = np.dot(V[:,:count].T, B) \n",
    "#         sub_A = np.dot(V[:,:count].T, W[:,:count])    \n",
    "#         #project sTDA_A matrix and vector B into subspace \n",
    "#         m = np.shape(sub_A)[0]\n",
    "# #         print ('subaspace size = ', m)\n",
    "# #         print ('check V1', check_orthonormal(V[:,:count]))\n",
    "#         #m is always the size of subspace\n",
    "# #         print ('Size of subspace =', m)\n",
    "#         # size of subspace\n",
    "# #         sub_guess = scipy.linalg.solve_sylvester(sub_A, - Lambda, sub_B)   \n",
    "#         #scipy.linalg.solve_sylvester(A,B,Q) # solve equation AX + XB = Q\n",
    "#         sub_guess = solve_AX_Xla_B(sub_A, eigen_lambda, sub_B)\n",
    "# #         print ('shape of sub_guess = ', np.shape(sub_guess))\n",
    "# #         print ('shape of V = ', np.shape(V))\n",
    "# #         sub_guess = Gram_Schdmit(sub_guess)\n",
    "#         full_guess = np.dot(V[:,:count], sub_guess)\n",
    "# #         print ('shape of full_guess = ', np.shape(full_guess))\n",
    "# #         print ('shape of sTDA_fly(full_guess) = ', np.shape(sTDA_fly(full_guess)))\n",
    "# #         print ('shape of eigen_lambda * full_guess = ', np.shape(eigen_lambda * full_guess))       \n",
    "        \n",
    "#         residual = np.dot(W[:,:count], sub_guess) - full_guess*eigen_lambda - B  \n",
    "#         data_dict['Precondition']\n",
    "# #         print ('shape of residual rrrrrrr= ', np.shape(residual))   \n",
    "#         Norms_of_r = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "#         if i == 0:\n",
    "#             initial_residual = Norms_of_r\n",
    "# #         print ('Norms_of_r =', Norms_of_r)\n",
    "\n",
    "# #         print ('shape of Norm =', np.shape(Norms_of_r))\n",
    "        \n",
    "#         max_norm = np.max(Norms_of_r)\n",
    "        \n",
    "# #         print ('max_norm = ', max_norm)\n",
    "#         if max_norm < tol:\n",
    "#             break\n",
    "#         index = [i for i in range(np.shape(Norms_of_r)[1]) if Norms_of_r[0,i] > tol]\n",
    "#         # index for not converged residuals\n",
    "# #         print ('index =',index)\n",
    "\n",
    "# #         print ('shape of residaul =', np.shape(residual))\n",
    "        \n",
    "#         # preconditioning step\n",
    "#         # only generate new guess from unconverged residuals\n",
    "#         new_guess = residual[:,index]/D[:,index]\n",
    "# #         print ('shape of new_guess =', np.shape(new_guess))\n",
    "# #         print ('shape of new_guess0 =', np.shape(new_guess))\n",
    "# #         print ('check new_guess', check_orthonormal(new_guess))\n",
    "#         V, new_count = Gram_Schdmit_fill_holder (V, count, new_guess)\n",
    "#         W[:, count:new_count] = sTDA_fly(V[:, count:new_count])\n",
    "#         count = new_count\n",
    "        \n",
    "        \n",
    "#         xxxx = check_orthonormal(V[:,:count])\n",
    "# #         print ('check orthonormal of V', xxxx)\n",
    "#         if xxxx > 1e-5:\n",
    "#             print ('Warning! Orthonormalily of V breaking down after ',i, ' steps')\n",
    "#             print ('n_residuals: ', N_vectors)\n",
    "#             print ('initial residual norms', initial_residual)\n",
    "#             print ('current residual norms', Norms_of_r)\n",
    "#             break\n",
    "# #         if i%10 == 0 and i!= 0:\n",
    "# #         V[:,:count] = Gram_Schdmit(V[:,:count])\n",
    "# #         add new guess to the guess space\n",
    "# #     print ('max_norm = ',max_norm)\n",
    "#     if i == (max -1):\n",
    "#         print ('============sTDA preconditioner Failed due to iteration limmit==============')\n",
    "#         print ('initial residual norms', initial_residual)\n",
    "#         print ('current residual norms', Norms_of_r)\n",
    "#         print ('check orthonormal of V', xxxx)\n",
    "#         print ('max_norm = ', max_norm)\n",
    "#     elif max_norm < tol:\n",
    "#         print ('======================Converged!=================')\n",
    "#         print ('converged after ', i, 'steps')\n",
    "#     elif max_norm >= tol:\n",
    "#         print ('================sTDA preconditioner Failed to converge=====================')\n",
    "# #     print ('n_residuals: ', N_vectors)\n",
    "#     end = time.time()\n",
    "# #     print ('                                                        Time: ', round(end-start,4))\n",
    "    \n",
    "    \n",
    "# #     print ('Iteration_steps =', i)\n",
    "# #     print ('final orthonormalily of V', check_orthonormal(V[:,:count]))\n",
    "\n",
    "# #     print ('Size of subspace =', m)\n",
    "#     return (full_guess*bnorm)\n",
    "\n",
    "\n",
    "# ###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # on_the_fly_sTDA_preconditioner() testing block\n",
    "\n",
    "# B = np.random.random ((occupied*virtual,1))\n",
    "# B = np.append(B,B, axis = 1)\n",
    "# B = np.append(B,B, axis = 1)\n",
    "# B = np.append(B,B, axis = 1)\n",
    "# print (np.shape(B))\n",
    "\n",
    "# Y = None\n",
    "\n",
    "# eigen_lambda = (10.3,10.1,10.1,10.1,10.6,10.2,10.7,10.1)\n",
    "\n",
    "\n",
    "# preconditioned_B =  on_the_fly_sTDA_preconditioner (B, eigen_lambda, Y)\n",
    "\n",
    "# # print ('Norm of preconditioned_B', np.linalg.norm(preconditioned_B))\n",
    "\n",
    "# true_answer = scipy.linalg.solve_sylvester(sTDA_A, -np.diag(eigen_lambda), B)\n",
    "\n",
    "# # print ('Norm of true_answer     ',np.linalg.norm(true_answer))\n",
    "# # print (np.shape(true_answer))\n",
    "\n",
    "# #     print ('Norm of difference: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "# # print (np.shape(true_answer - preconditioned_B))\n",
    "\n",
    "# preconditioned_B = preconditioned_B/np.linalg.norm(preconditioned_B)\n",
    "# true_answer = true_answer/np.linalg.norm(true_answer)\n",
    "# print ('difference of true solution: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "# print ('_____________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on_the_fly_sTDA_preconditioner() testing block\n",
    "\n",
    "\n",
    "# eigens = [11.00156018, 11.42586088,11.81597338,12.53032618,12.68694181,13.15229166,13.1853657,13.32624103,13.50252777,13.86457637]\n",
    "\n",
    "# Eigens_noise = [i + 2*np.random.rand() for i in eigens]\n",
    "\n",
    "# print ('Eigens_noise', Eigens_noise)\n",
    "# for n_residuals in range (1,10):\n",
    "    \n",
    "#     B = np.random.random ((occupied*virtual, n_residuals))\n",
    "\n",
    "#     Y = None\n",
    "\n",
    "#     eigen_lambda = Eigens_noise[:n_residuals]\n",
    "    \n",
    "# #     print ('n_residuals = ',n_residuals)\n",
    "#     print ('                                                                    ')\n",
    "#     print ('                                                                    ')\n",
    "#     print ('______________________________________________________________Begins')\n",
    "#     preconditioned_B =  on_the_fly_sTDA_preconditioner (B, eigen_lambda, Y)\n",
    "#     # print ('Norm of preconditioned_B', np.linalg.norm(preconditioned_B))\n",
    "#     true_answer = scipy.linalg.solve_sylvester(sTDA_A, -np.diag(eigen_lambda), B)\n",
    "\n",
    "#     # print ('Norm of true_answer     ',np.linalg.norm(true_answer))\n",
    "#     # print (np.shape(true_answer))\n",
    "\n",
    "# #     print ('Norm of difference: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "#     # print (np.shape(true_answer - preconditioned_B))\n",
    "\n",
    "#     preconditioned_B = preconditioned_B/np.linalg.norm(preconditioned_B)\n",
    "#     true_answer = true_answer/np.linalg.norm(true_answer)\n",
    "#     print ('difference of true solution: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "#     print ('________________________________________________________________End')\n",
    "# # residual size: 351\n",
    "# # convergence threshold = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# def A_diag_initial_guess (k):\n",
    "#     m = min([2*k, k+8, occupied*virtual])\n",
    "#     # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "#     # m=k works for H2, m=4k works for H2O\n",
    "#     V = np.zeros((n, 30*k)) \n",
    "#     #array of zeros, a container to hold current guess vectors \n",
    "#     W = np.zeros((n, 30*k)) \n",
    "    \n",
    "#     sort = hdiag.argsort()\n",
    "#     for j in range(0,m):\n",
    "#         V[int(np.argwhere(sort == j)), j] = 1   \n",
    "#         # positions with lowest values set as 1\n",
    "#         W[:, j] = vind(V[:, j].T).T\n",
    "#     # W = Av, create transformed guess vectors\n",
    "\n",
    "#     return (m, V, W)\n",
    "\n",
    "# def sTDA_initial_guess (k):\n",
    "#     m = min([2*k, k+8, occupied*virtual])\n",
    "#     print ('initial subspace size m = ', m)\n",
    "#     # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "#     # m=k works for H2, m=4k works for H2O\n",
    "#     V = np.zeros((n, 30*k)) \n",
    "#     # array of zeros, a container to hold current guess vectors, v\n",
    "#     W = np.zeros((n, 30*k)) \n",
    "#     # a container to hold transformed guess vectors, Av\n",
    "#     eigvalues, eigkets = np.linalg.eigh(sTDA_A)\n",
    "#     # eigv, eigk = Davidson (A, m, 1e-5, default_initial_guess, A_diag_preconditioner)\n",
    "#     #!!!!!!!! diagonalize sTDA_A amtrix\n",
    "#     V[:, :m] = eigkets [:, :m]\n",
    "# #     V[:, :m]= Gram_Schdmit (V[:, :m])\n",
    "#     W[:, :m] = vind(V[:,:m].T).T  \n",
    "#     return (m, V, W)\n",
    "# ######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# ###################################################################\n",
    "# def A_diag_preconditioner (residual, sub_eigenvalue):\n",
    "# #     D = hdiag - sub_eigenvalue\n",
    "# #     zz = 1e-14\n",
    "# #     D[(D<zz)&(D>=0)] = zz\n",
    "# #     D[(D>-zz)&(D<0)] = -zz \n",
    "# #     #kick out all small values  \n",
    "# #     new_vec = residual/D\n",
    "#     zz = 1e-8\n",
    "#     D = np.zeros((n, k))\n",
    "#     for i in range (0, k):\n",
    "#         D[:,i] = hdiag - sub_eigenvalue[i]\n",
    "#         D[:,i][(D[:,i]<zz)&(D[:,i]>=0)] = zz\n",
    "#         D[:,i][(D[:,i]>-zz)&(D[:,i]<0)] = -zz\n",
    "\n",
    "#     new_guess = residual/D\n",
    "\n",
    "#     return new_guess\n",
    "\n",
    "\n",
    "\n",
    "# # def on_the_fly_sTDA_preconditioner(residual, sub_eigenvalue):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# ####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# def Davidson (k, tol, initial_guess, preconditioner):\n",
    "\n",
    "#     if initial_guess == 'sTDA_initial_guess':\n",
    "#         initial_guess = sTDA_initial_guess\n",
    "#         print ('Initial guess: sTDA A matrix')\n",
    "#     elif initial_guess == 'A_diag_initial_guess':\n",
    "#         initial_guess = A_diag_initial_guess\n",
    "#         print ('Initial guess: Diagonal of Pseudo A matrix')\n",
    "        \n",
    "#     if preconditioner == 'sTDA_fly_preconditioner':\n",
    "#         preconditioner = on_the_fly_sTDA_preconditioner\n",
    "#         print ('Preconditioner: on-the-fly sTDA A matrix')\n",
    "        \n",
    "#     elif preconditioner == 'A_diag_preconditioner':\n",
    "#         preconditioner = A_diag_preconditioner\n",
    "#         print ('Preconditioner: Diagonal of Pseudo A matrix')\n",
    "#     start = time.time()\n",
    "    \n",
    "#     #tol = 1e-5      \n",
    "#     # Convergence tolerance\n",
    "#     n = occupied*virtual\n",
    "#     max = 29     \n",
    "#     # Maximum number of iterations\n",
    "    \n",
    "#     #################################################\n",
    "#     # generate initial guess\n",
    "#     m, V, W = initial_guess(k)\n",
    "#     #generate initial guess and put in holders V and W\n",
    "#     # m is size of subspace\n",
    "# #     print ('Initial guess done')\n",
    "   \n",
    "#     ########################################################################################### \n",
    "#     for i in range(0, max):\n",
    "# #         print ('Iteration = ', i)\n",
    "# #         sum_convec = 0\n",
    "#         # total converged eigenvectors\n",
    "#         # breaf if sum_convec == k\n",
    "#         sub_A = np.dot(V[:,:m].T, W[:,:m])  \n",
    "# #         m = np.shape(sub_A)[1]\n",
    "# #         print ('shape of subspace = ', m)\n",
    "#         # sub_A is subspace A matrix\n",
    "        \n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "\n",
    "# #         eigen_lambda = sub_eigenvalue[:k]\n",
    "# #         print ('sub_eigenvalue =', sub_eigenvalue*27.21138624598853)\n",
    "#         #diagonal elements are smallest k eigenvalues\n",
    "          \n",
    "# #         print ('W[:,:m] =',np.shape((W[:,:m])))\n",
    "# #         print ('sub_eigenket[:,:k] =',np.shape(sub_eigenket[:,:k]))\n",
    "# #         print ('V[:,:m] =',np.shape(V[:,:m]))\n",
    "# #         print ('eigen_lambda =', np.shape(eigen_lambda))\n",
    "\n",
    "#         residual = np.dot(W[:,:m], sub_eigenket[:,:k]) - np.dot(V[:,:m], sub_eigenket[:,:k] * sub_eigenvalue[:k])\n",
    "        \n",
    "#         Norms_of_r = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "# #         print ('Norms of r =', Norms_of_r)\n",
    "\n",
    "#         max_norm = np.max(Norms_of_r)\n",
    "# #         print ('max_norm = ', max_norm)\n",
    "#         if max_norm < tol:\n",
    "#             break\n",
    "        \n",
    "#         index = [i for i in range(np.shape(Norms_of_r)[1]) if Norms_of_r[0,i] > tol]\n",
    "# #         print ('index =', index)\n",
    "#         # index for unconverged residuals\n",
    "       \n",
    "        \n",
    "#         ########################################\n",
    "#         # preconditioning step\n",
    "#         # only generate new guess from unconverged residuals\n",
    "#         Y = None\n",
    "#         new_guess = on_the_fly_sTDA_preconditioner (residual[:,index], sub_eigenvalue[:k][index])\n",
    "        \n",
    "#         # new_guess = precondition (residual[:,index], sub_eigenvalue[:k][index])\n",
    "    \n",
    "#         V, new_m = Gram_Schdmit_fill_holder (V, m, new_guess)\n",
    "        \n",
    "# #         print ('norms of V = ', np.linalg.norm (V, axis=0, keepdims = True))\n",
    "        \n",
    "#         W[:, m:new_m] = vind (V[:, m:new_m].T).T\n",
    "        \n",
    "#         m = new_m\n",
    "        \n",
    "#         xxxx = check_orthonormal(V[:,:m])\n",
    "# #         print ('Orthonormality of V = ', xxxx)\n",
    "# #         print ('size of subspace = ', m)\n",
    "        \n",
    "        \n",
    "#     ########################################################################################### \n",
    "\n",
    "#     Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "#     print ('Iteration steps =', i+1)\n",
    "#     print ('Final subspace size = ', np.shape(sub_A))\n",
    "#     #print ('Davidson time:', round(end-start,4))\n",
    "    \n",
    "#     return (sub_eigenvalue[:k]*27.21138624598853, Eigenkets[:,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('#################################################################')\n",
    "# print ('In-house Davidson codes:')\n",
    "\n",
    "# k = 30\n",
    "# tol = 1e-5\n",
    "# # initial_guess = 'sTDA_initial_guess'\n",
    "# # preconditioner = 'sTDA_fly_preconditioner'\n",
    "\n",
    "# print ('Number of excited states =', k)\n",
    "# print ('Residual convergenve threshold =', tol)\n",
    "\n",
    "# print ('#################################################################')\n",
    "\n",
    "# start = time.time()\n",
    "# Excitation_energies, kets = Davidson (k, tol, 'sTDA_initial_guess', 'sTDA_fly_preconditioner')\n",
    "# end = time.time()\n",
    "\n",
    "# print ('In-house Davidson time= ', end - start)\n",
    "# print ('Excited State energies (eV) =')\n",
    "# print (Excitation_energies)\n",
    "\n",
    "# print ('#################################################################')\n",
    "# # TDA_TDDFT 8.73907144 10.77713239 11.26755041 12.203639   12.27658757 12.69784956 12.84428532 13.49469905 13.54369257 13.98420242\n",
    "# # sTDA      12.2388045  13.59944497 13.79151538 15.04073066 15.10727607 15.24503727 16.45336705 16.51809479 16.8506097  17.3015488 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('PySCF TDA-TDDFT codes:')\n",
    "# start = time.time()\n",
    "# td.conv_tol = 1e-13\n",
    "# td.nstates = k\n",
    "# td.kernel()\n",
    "# end = time.time()\n",
    "# print ('PySCF Davidson time= ', end - start)\n",
    "# print ('#################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I = np.eye(occupied*virtual)\n",
    "# full_A_marix = vind (I).T\n",
    "# e,v = np.linalg.eigh(full_A_marix)\n",
    "\n",
    "# print (e[:k]*27.21138624598853)  #27.211396132\n",
    "# # print (e[:k]*27.21138610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################################################################################\n",
    "# def on_the_fly_sTDA_preconditioner111111 (B, eigen_lambda, Y=0): \n",
    "#     # (sTDA_A - eigen_lambda*I)^-1 B = X \n",
    "#     # AX - X\\lambda = B\n",
    "\n",
    "#     # columns of B are the vectors to be preconditioned, \n",
    "#     n = np.shape(B)[0]\n",
    "    \n",
    "#     B = B.reshape(n,-1)\n",
    "\n",
    "#     N_vectors = np.shape(B)[1]\n",
    "#     #number of vectors to be preconditioned\n",
    "    \n",
    "#     bnorm = np.linalg.norm(B, axis=0, keepdims = True)\n",
    "#     #norm of each vectors in B, shape (1,-1)\n",
    "#     B = B/bnorm\n",
    "# #     print ('shape of B=', np.shape(B))\n",
    "#     start = time.time()\n",
    "#     tol = 1e-5     # Convergence tolerance\n",
    "#     max = 30      # Maximum number of iterations  \n",
    "    \n",
    "#     diag = delta_diag_A.flatten()\n",
    "# #     # delta_diag_A.flatten() is (\\spsilon_a-\\spsilon_i)\n",
    "\n",
    "#     D = np.zeros([n,N_vectors])\n",
    "#     for i in range (0, N_vectors):\n",
    "#         D[:,i] = diag - eigen_lambda[i]\n",
    "# #         D[:,i][(D[:,i]<1e-16)&(D[:,i]>=0)] = 1e-20\n",
    "# #         D[:,i][(D[:,i]>-1e-16)&(D[:,i]<0)] = -1e-20\n",
    "#     #D is preconditioner for each state \n",
    "#     print ('shape of D =', np.shape(D))\n",
    "#     ###########################################\n",
    "#     #initial guess: (diag(A) - \\lambda)^-1 B.\n",
    "#     V = B/D\n",
    "#     V = Gram_Schdmit(V)\n",
    "#     print ('shape of V =', np.shape(V))\n",
    "    \n",
    "#     W = sTDA_fly(V) \n",
    "#     #V is guess holder, \n",
    "#     # at the end of each iteration, V will be appended with new guess vectors\n",
    "    \n",
    "#     Lambda = np.diag(eigen_lambda)\n",
    "\n",
    "#     ####################################################################################\n",
    "#     # Begin iterations\n",
    "#     for i in range (0, max):\n",
    "#         print ('Iteration =', i)\n",
    "#         sub_B = np.dot(V.T, B) \n",
    "#         sub_A = np.dot(V.T, W)    \n",
    "#         #project sTDA_A matrix and vector B into subspace \n",
    "#         m = np.shape(sub_A)[0]\n",
    "# #         print ('subaspace size = ', m)\n",
    "#         print ('check V', np.linalg.norm(np.dot(V.T, V)- np.eye(m)))\n",
    "#         #m is always the size of subspace\n",
    "\n",
    "#         # size of subspace\n",
    "#         sub_guess = scipy.linalg.solve_sylvester(sub_A, - Lambda, sub_B)   \n",
    "#         #scipy.linalg.solve_sylvester(A,B,Q) # solve equation AX + XB = Q\n",
    "# #         print ('shape of sub_guess = ', np.shape(sub_guess))\n",
    "# #         print ('shape of V = ', np.shape(V))\n",
    "       \n",
    "#         full_guess = np.dot(V, sub_guess)\n",
    "# #         print ('shape of full_guess = ', np.shape(full_guess))\n",
    "# #         print ('shape of sTDA_fly(full_guess) = ', np.shape(sTDA_fly(full_guess)))\n",
    "# #         print ('shape of eigen_lambda * full_guess = ', np.shape(eigen_lambda * full_guess))       \n",
    "        \n",
    "#         residual = sTDA_fly(full_guess) - full_guess*eigen_lambda - B  \n",
    "        \n",
    "# #         print ('shape of residual rrrrrrr= ', np.shape(residual))   \n",
    "#         Norms_of_residual = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "#         print ('Norms_of_residual =', Norms_of_residual)\n",
    "\n",
    "# #         print ('shape of Norm =', np.shape(Norms_of_residual))\n",
    "        \n",
    "#         max_norm = np.max(Norms_of_residual)\n",
    "        \n",
    "#         print ('max_norm = ', max_norm)\n",
    "#         if max_norm < tol:\n",
    "#             break\n",
    "# #         index = np.where(max_norm < tol)\n",
    "# #         D[:, index] = 1\n",
    "#         guess = residual/D \n",
    "#         #preconditioning step\n",
    "\n",
    "# #         V = Gram_Schdmit_append(V, guess)\n",
    "#         V = np.append(V, guess, axis = 1)\n",
    "#         V = Gram_Schdmit(V)\n",
    "# #         W = np.append(W, sTDA_fly(guess), axis=1)\n",
    "#         W = sTDA_fly(V)\n",
    "#         # add new guess to the guess space\n",
    "#     ####################################################################################      \n",
    "\n",
    "#     #########################################################################################\n",
    "# #    print ('sTDA_Iteration steps =', i)\n",
    "#     end = time.time()\n",
    "#     print ('sTDA_Precondition time:', round(end-start,4))\n",
    "\n",
    "# # del list[n]\n",
    "# # A = np.delete(A, n, axis=1)\n",
    "\n",
    "#     return (full_guess*bnorm)\n",
    "# #     return (full_guess)\n",
    "# ###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# Qmatrix = [(generateQ(atom_id)) for atom_id in range (0, Natm)]\n",
    "# #a list of q matrix\n",
    "# end = time.time()\n",
    "\n",
    "# Qmatrix = np.asarray(Qmatrix)\n",
    "# print (end - start)\n",
    "# print (np.shape(Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# def Davidson1 (k, tol, initial_guess, preconditioner):\n",
    "\n",
    "#     if initial_guess == 'sTDA_initial_guess':\n",
    "#         initial_guess = sTDA_initial_guess\n",
    "#         print ('Initial guess: sTDA A matrix')\n",
    "#     elif initial_guess == 'A_diag_initial_guess':\n",
    "#         initial_guess = A_diag_initial_guess\n",
    "#         print ('Initial guess: Diagonal of Pseudo A matrix')\n",
    "        \n",
    "#     if preconditioner == 'sTDA_fly_preconditioner':\n",
    "#         preconditioner = on_the_fly_sTDA_preconditioner\n",
    "#         print ('Preconditioner: on-the-fly sTDA A matrix')\n",
    "        \n",
    "#     elif preconditioner == 'full_sTDA_preconditioner':\n",
    "#         preconditioner = sTDA_preconditioner\n",
    "#         print ('Preconditioner: full sTDA A matrix')\n",
    "        \n",
    "#     elif preconditioner == 'A_diag_preconditioner':\n",
    "#         preconditioner = A_diag_preconditioner\n",
    "#         print ('Preconditioner: Diagonal of Pseudo A matrix')\n",
    "#     start = time.time()\n",
    "    \n",
    "#     #tol = 1e-5      \n",
    "#     # Convergence tolerance\n",
    "#     n = occupied*virtual\n",
    "#     max = 90      \n",
    "#     # Maximum number of iterations\n",
    "\n",
    "#     ########################################################################################### \n",
    "#     for i in range(0, max):\n",
    "#         print ('Iteration = ', i)\n",
    "#         sum_convec = 0\n",
    "#         # total converged eigenvectors\n",
    "#         # breaf if sum_convec == k\n",
    "        \n",
    "#         #################################################\n",
    "#         # generate initial guess\n",
    "#         if i == 0:\n",
    "#             m, V, W = initial_guess(k)\n",
    "#         print ('Initial guess done')\n",
    "#         #################################################\n",
    "\n",
    "#         sub_A = np.dot(V.T, W)  \n",
    "#         # sub_A is subspace A matrix\n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "\n",
    "#         lasit_newvec = 0\n",
    "#         # amount of new vectors added in last iteration, ranging from 1 to k\n",
    "#         # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "\n",
    "        \n",
    "#         eigen_lambda = sub_eigenvalue[:k]\n",
    "#         #diagonal elements are smallest k eigenvalues\n",
    "      \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         for x in range(0,k):      \n",
    "#             #looking at first k vecrors one by one, check whether they are roots\n",
    "#             residual = np.dot((W[:,:m]- sub_eigenvalue[x]*V[:,:m].reshape(n,-1)), sub_eigenket[:,x])\n",
    "#             # residual = A (Vs) - lambda*(Vs) \n",
    "#             # Vs np.dotV([:,:m])s[:,x]), projects the subspace eigenket back to full space\n",
    "            \n",
    "#             #print ('Residual created')\n",
    "        \n",
    "\n",
    "#             norm = np.linalg.norm(residual)\n",
    "#             if norm <= tol:\n",
    "#                 sum_convec += 1\n",
    "#             else:\n",
    "#                 # current guess is not good enough, \n",
    "#                 # so we use current guess to create new guess vectors\n",
    "#                 #########################################################\n",
    "#                 new_vec = preconditioner (residual, sub_eigenvalue[x])          \n",
    "#                 #########################################################\n",
    "#                 # preconditioner\n",
    "                \n",
    "#                 new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "#                 new_vec = new_vec.reshape(-1,1)\n",
    "#                 # normalize before Gram-Schmidt \n",
    "#                 for y in range (0, m + lasit_newvec):  \n",
    "#                     # orthonormalize the new vector against all old vectors\n",
    "#                     new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y].reshape(-1,1)   \n",
    "                    \n",
    "#                 norm = np.linalg.norm (new_vec)\n",
    "#                 if norm > 1e-16:\n",
    "#                     new_vec = new_vec/norm\n",
    "#                     # normalzie the new vector, now Gram-Schmidt is done\n",
    "\n",
    "                    \n",
    "#                     V = np.append (V, new_vec, axis=1)\n",
    "#                     # put the new guess into container\n",
    "                    \n",
    "#                     trans_new_vec = vind(new_vec)\n",
    "#                     #print ('Shape of trans_new_vec =', np.shape(trans_new_vec)) = (1,351)\n",
    "#                     W = np.append (W, trans_new_vec.T, axis = 1)\n",
    "#                     # put transformed guess Av into container\n",
    "#                     lasit_newvec += 1\n",
    "#         ####################################################################################      \n",
    "#         if sum_convec == k:\n",
    "#             break\n",
    "#         m += lasit_newvec\n",
    "#     ########################################################################################### \n",
    "\n",
    "#     Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "    \n",
    "#     print ('Iteration steps =', i+1)\n",
    "#     print ('Final subspace size = ', np.shape(sub_A))\n",
    "#     #print ('Davidson time:', round(end-start,4))\n",
    "    \n",
    "#     return (sub_eigenvalue[:k]*27.21138624598853, Eigenkets[:,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define two electron intergeral (pq|rs)\n",
    "# Natm = mol.natm \n",
    "# #number of atoms\n",
    "# Natm = mol.natm \n",
    "\n",
    "# def ele_intJ (i,j,a,b):\n",
    "#     ijab = 0\n",
    "#     for atom_A_id in range (0, Natm):\n",
    "#         for atom_B_id in range (0, Natm):\n",
    "#             ijab += Qmatrix[atom_A_id,i,j] * Qmatrix[atom_B_id,a,b] * GammaJ[atom_A_id, atom_B_id]\n",
    "#     return ijab\n",
    "        \n",
    "# def ele_intK (i,a,j,b):\n",
    "#     iajb = 0\n",
    "#     for atom_A_id in range (0, Natm):\n",
    "#         for atom_B_id in range (0, Natm):\n",
    "#             iajb += Qmatrix[atom_A_id,i,a] * Qmatrix[atom_B_id,j,b] * GammaK[atom_A_id, atom_B_id]\n",
    "#     return iajb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# def Davidson2 (k, tol, initial_guess, preconditioner):\n",
    "\n",
    "#     if initial_guess == 'sTDA_initial_guess':\n",
    "#         initial_guess = sTDA_initial_guess\n",
    "#         print ('Initial guess: sTDA A matrix')\n",
    "#     elif initial_guess == 'A_diag_initial_guess':\n",
    "#         initial_guess = A_diag_initial_guess\n",
    "#         print ('Initial guess: Diagonal of Pseudo A matrix')\n",
    "        \n",
    "#     if preconditioner == 'sTDA_fly_preconditioner':\n",
    "#         preconditioner = on_the_fly_sTDA_preconditioner\n",
    "#         print ('Preconditioner: on-the-fly sTDA A matrix')\n",
    "        \n",
    "#     elif preconditioner == 'full_sTDA_preconditioner':\n",
    "#         preconditioner = sTDA_preconditioner\n",
    "#         print ('Preconditioner: full sTDA A matrix')\n",
    "        \n",
    "#     elif preconditioner == 'A_diag_preconditioner':\n",
    "#         preconditioner = A_diag_preconditioner\n",
    "#         print ('Preconditioner: Diagonal of Pseudo A matrix')\n",
    "#     start = time.time()\n",
    "    \n",
    "#     #tol = 1e-5      \n",
    "#     # Convergence tolerance\n",
    "#     n = occupied*virtual\n",
    "#     max = 90      \n",
    "#     # Maximum number of iterations\n",
    "\n",
    "#     ########################################################################################### \n",
    "#     for i in range(0, max):\n",
    "#         print ('Iteration = ', i)\n",
    "#         sum_convec = 0\n",
    "#         # total converged eigenvectors\n",
    "#         # breaf if sum_convec == k\n",
    "        \n",
    "#         #################################################\n",
    "#         # generate initial guess\n",
    "#         if i == 0:\n",
    "#             m, V, W = initial_guess(k)\n",
    "#         print ('Initial guess done')\n",
    "#         #################################################\n",
    "\n",
    "#         sub_A = np.dot(V.T, W)  \n",
    "#         # sub_A is subspace A matrix\n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "\n",
    "#         lasit_newvec = 0\n",
    "#         # amount of new vectors added in last iteration, ranging from 1 to k\n",
    "#         # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "\n",
    "        \n",
    "#         ####################################################################################\n",
    "#         for x in range(0,k):      \n",
    "#             #looking at first k vecrors one by one, check whether they are roots\n",
    "#             residual = np.dot((W[:,:m]- sub_eigenvalue[x]*V[:,:m].reshape(n,-1)), sub_eigenket[:,x])\n",
    "#             # residual = A (Vs) - lambda*(Vs) \n",
    "#             # Vs np.dotV([:,:m])s[:,x]), projects the subspace eigenket back to full space\n",
    "            \n",
    "#             #print ('Residual created')\n",
    "        \n",
    "\n",
    "#             norm = np.linalg.norm(residual)\n",
    "#             if norm <= tol:\n",
    "#                 sum_convec += 1\n",
    "#             else:\n",
    "#                 # current guess is not good enough, \n",
    "#                 # so we use current guess to create new guess vectors\n",
    "#                 #########################################################\n",
    "#                 new_vec = preconditioner (residual, sub_eigenvalue[x])          \n",
    "#                 #########################################################\n",
    "#                 # preconditioner\n",
    "                \n",
    "#                 new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "#                 new_vec = new_vec.reshape(-1,1)\n",
    "#                 # normalize before Gram-Schmidt \n",
    "#                 for y in range (0, m + lasit_newvec):  \n",
    "#                     # orthonormalize the new vector against all old vectors\n",
    "#                     new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y].reshape(-1,1)   \n",
    "                    \n",
    "#                 norm = np.linalg.norm (new_vec)\n",
    "#                 if norm > 1e-16:\n",
    "#                     new_vec = new_vec/norm\n",
    "#                     # normalzie the new vector, now Gram-Schmidt is done\n",
    "\n",
    "                    \n",
    "#                     V = np.append (V, new_vec, axis=1)\n",
    "#                     # put the new guess into container\n",
    "                    \n",
    "#                     trans_new_vec = vind(new_vec)\n",
    "#                     #print ('Shape of trans_new_vec =', np.shape(trans_new_vec)) = (1,351)\n",
    "#                     W = np.append (W, trans_new_vec.T, axis = 1)\n",
    "#                     # put transformed guess Av into container\n",
    "#                     lasit_newvec += 1\n",
    "#         ####################################################################################      \n",
    "#         if sum_convec == k:\n",
    "#             break\n",
    "#         m += lasit_newvec\n",
    "#     ########################################################################################### \n",
    "\n",
    "#     Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "    \n",
    "#     print ('Iteration steps =', i+1)\n",
    "#     print ('Final subspace size = ', np.shape(sub_A))\n",
    "#     #print ('Davidson time:', round(end-start,4))\n",
    "    \n",
    "#     return (sub_eigenvalue[:k]*27.21138624598853, Eigenkets[:,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sTDA_A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigv,eigk = np.linalg.eigh(sTDA_A)\n",
    "print (eigv[:5]*27.21138624598853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (check_symmetric(A, tol=1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.linalg.norm(sTDA_A - sTDA_fly(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natm = mol.natm \n",
    "# def generateQ_ij ():\n",
    "#     q = np.zeros([Natm, occupied, occupied])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, occupied):\n",
    "#             for p in range (0, occupied):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu,i]*C[mu,p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# def generateQ_ab ():\n",
    "#     q = np.zeros([Natm, virtual, virtual])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, virtual):\n",
    "#             for p in range (0, virtual):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu, occupied + i]*C[mu,occupied + p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# def generateQ_ia ():\n",
    "#     q = np.zeros([Natm, occupied, virtual])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, occupied):\n",
    "#             for p in range (0, virtual):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu,i]*C[mu, occupied + p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# start = time.time()\n",
    "# q_tensor_ij = generateQ_ij ()\n",
    "# q_tensor_ab = generateQ_ab ()\n",
    "# q_tensor_ia = generateQ_ia ()\n",
    "\n",
    "# end = time.time()\n",
    "# print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(A)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigv,eigk = np.linalg.eigh(A)\n",
    "# idx = eigv.argsort()\n",
    "# eigv = eigv[idx]    #eigenvalues\n",
    "# eigk = eigk[:,idx]          #eigenkets, m*m\n",
    "\n",
    "# #np.linalg.eigh guarantees you that the eigenvalues are sorted and uses a faster algorithm \n",
    "# #that takes advantage of the fact that the matrix is symmetric. \n",
    "\n",
    "# print (np.round (eigv[:10]*27.21138624598853,4))   \n",
    "# # ':n', first n elements; 'n:' all elements except firt n \n",
    "\n",
    "\n",
    "#methanol\n",
    "# a_x = 0.38\n",
    "# beta1= 1.86\n",
    "# beta2=0\n",
    "# alpha1= 0.9\n",
    "# alpha2=0\n",
    "#[12.2388 13.5994 13.7915 15.0407 15.1073 15.245  16.4534 16.5181 16.8506 17.3015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies, vectors = np.linalg.eigh(H)\n",
    "# print (energies[:5]*27.21138624598853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2O Excited State energies (eV)\n",
    "# [ 5.12051837  7.78183026  8.43305887  9.81364248 10.41186311]\n",
    "# [ 5.12051842  7.78183032  8.43305894  9.81364256 10.4118632 ]\n",
    "#\n",
    "\n",
    "\n",
    "#CH3OH Excited State energies (eV)\n",
    "#[ 8.73907144 10.77713239 11.26755041 12.203639   12.27658757]\n",
    "#[ 8.73907152 10.77713248 11.2675505  12.2036391  12.27658768]\n",
    "\n",
    "\n",
    "\n",
    "# CH3OH\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# sTDA A matrix as initial guess\n",
    "# sTDA A matrix as preconditioner\n",
    "# Iteration steps = 11\n",
    "# Davidson time: 0.3732\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# sTDA A matrix as initial guess\n",
    "# Diagonal of full A matrix as preconditioner\n",
    "# Iteration steps = 15\n",
    "# Davidson time: 0.3009\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# Diagonal of full A matrix as initial guess\n",
    "# Diagonal of full A matrix as preconditioner\n",
    "# Iteration steps = 15\n",
    "# Davidson time: 0.3152\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# Diagonal of full A matrix as initial guess\n",
    "# sTDA A matrix as preconditioner\n",
    "# Iteration steps = 11\n",
    "# Davidson time: 0.334\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def davidson_A_matrix_hstack (A, k): # matrix A and how many eignvalues to solve\n",
    "    \n",
    "#     start = time.time()\n",
    "\n",
    "#     tol = 1e-5      # Convergence tolerance\n",
    "#     max = 40      # Maximum number of iterations\n",
    "\n",
    "#     ###########################################################################################\n",
    "#     # Begin iterations\n",
    "#     for i in range(0, max):\n",
    "#         sum_convec = 0\n",
    "#         #total converged eigenvectors\n",
    "#         # if sum_convec == k, break\n",
    "        \n",
    "#         lasit_newvec = 0\n",
    "#         # it records amount of new vectors added in last iteration, ranging from 1 to k\n",
    "#         # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "        \n",
    "\n",
    "#         #################################################\n",
    "#         # generate initial guess\n",
    "#         if i == 0:\n",
    "#             #initial guess  \n",
    "#             n = np.shape(A)[0]\n",
    "#             m = k  \n",
    "#             # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "#             # m=k works for H2, m=4k works for H2O\n",
    "\n",
    "#             V = np.zeros((n, m)) #array of zeros, a container to hold current guess vectors\n",
    "            \n",
    "#             sort = np.diag(A).argsort()\n",
    "#             for j in range(0,m):\n",
    "#                 V[int(np.argwhere(sort == j)), j] = 1   \n",
    "#                 # positions with lowest values set as 1\n",
    "#             W = np.dot(A,V)   \n",
    "#             # W = Av, create transformed guess vectors\n",
    "#         #################################################\n",
    "        \n",
    "        \n",
    "#         sub_A = np.dot(V.T, W)  \n",
    "#         # sub_A is subspace A matrix\n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "        \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         for x in range(0,k):      \n",
    "#             #looking at first k vecrors one by one, check if they are roots\n",
    "#             residual = np.dot((W[:,:m]- sub_eiegnvalue[x]*V[:,:m]), sub_eigenket[:,x])\n",
    "#             # np.dotV([:,:m])s[:,x]) can transform the subspace-eigenket back into full space eigenket\n",
    "            \n",
    "#             norm = np.linalg.norm(residual)\n",
    "#             if norm <= tol:\n",
    "#                 sum_convec += 1\n",
    "#             else:\n",
    "#                 #print ('norm > tol')\n",
    "#                 # current guess is not good enough, \n",
    "#                 # so we use current guess to create new guess vectors\n",
    "#                 d = np.diag(A)-sub_eiegnvalue[x]\n",
    "#                 d[(d<1e-16)&(d>=0)] = 1e-16\n",
    "#                 d[(d>-1e-16)&(d<0)] = -1e-16   \n",
    "#                 # kick out all small values\n",
    "#                 new_vec = residual/d          \n",
    "#                 # preconditioner\n",
    "                \n",
    "#                 new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "#                 # normalize before Gram-Schmidt \n",
    "\n",
    "#                 for y in range (0, m + lasit_newvec):  \n",
    "#                     # orthonormalize the new vector against all old vectors\n",
    "#                     new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y]   \n",
    "                    \n",
    "#                 norm = np.linalg.norm (new_vec)\n",
    "#                 if norm > 1e-16:\n",
    "#                     new_vec = new_vec/norm\n",
    "#                     # normalzie the new vector, now Gram-Schmidt is done\n",
    "                    \n",
    "#                     V = np.append (V, new_vec[:, None], axis=1)\n",
    "#                     # put the new guess into container\n",
    "                    \n",
    "#                     W = np.append (W, np.dot(A, new_vec)[:, None], axis = 1)\n",
    "#                     # put transformed guess Av into container\n",
    "                    \n",
    "#                     lasit_newvec += 1\n",
    "#         ####################################################################################      \n",
    "#         if sum_convec == k:\n",
    "#             break\n",
    "#         m += lasit_newvec\n",
    "#     ########################################################################################### \n",
    "#     print ('Iteration steps =', i+1)\n",
    "\n",
    "#     end = time.time()\n",
    "#     Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "#     print ('Davidson time (no vind function):', round(end-start,4))\n",
    "#     # return (sub_eiegnvalue[:k], Eigenkets[:,:k])\n",
    "#     return (sub_eiegnvalue[:k]*27.21138624598853)\n",
    "\n",
    "# #print (davidson_A_matrix_hstack (A, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nocc = mol.nelectron \n",
    "# mol.nelectron is number of electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
