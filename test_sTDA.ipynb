{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy import *\n",
    "import matplotlib.pylab as plt\n",
    "import operator\n",
    "import pyscf\n",
    "from pyscf import gto, scf, dft, tddft, data\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='Davidson')\n",
    "\n",
    "# parser.add_argument('-c', '--filename',       type=str, default='methanol.xyz', help='input filename')\n",
    "# parser.add_argument('-m', '--method',         type=str, default='RKS', help='RHF RKS UHF UKS')\n",
    "# parser.add_argument('-f', '--functional',     type=str, default='b3lyp', help='xc functional')\n",
    "# parser.add_argument('-b', '--basis_set',      type=str, default='def2-SVP', help='basis sets')\n",
    "# parser.add_argument('-i', '--initial_guess',  type=str, default='sTDA_A', help='initial_guess: diag_A or sTDA_A')\n",
    "# parser.add_argument('-p', '--preconditioner', type=str, default='sTDA_A', help='preconditioner: diag_A or sTDA_A')\n",
    "# parser.add_argument('-t', '--tolerance',      type=float, default='1e-5', help='residual norm convergence threshold')\n",
    "# parser.add_argument('-n', '--nstates',        type=int, default='4', help='number of excited states')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# ################################################\n",
    "# # read xyz file and delete its first two lines\n",
    "# f = open(args.filename)\n",
    "# coordinates = f.readlines()\n",
    "# del coordinates[:2]\n",
    "# ################################################\n",
    "\n",
    "# print ('args.method =', args.method)\n",
    "# ###########################################################################\n",
    "# # build geometry in PySCF\n",
    "# mol = gto.Mole()\n",
    "# print (2)\n",
    "# mol.build(atom = coordinates, basis = args.basis_set, symmetry = True)\n",
    "# print (3)\n",
    "# ###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions (linewidth=300)\n",
    "\n",
    "elements = ['H' , 'He', 'Li', 'Be', 'B' , 'C' , 'N' , 'O' , 'F' , 'Ne',\n",
    "    'Na', 'Mg', 'Al', 'Si', 'P' , 'S' , 'Cl', 'Ar', 'K' , 'Ca',\n",
    "    'Sc', 'Ti', 'V' , 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',\n",
    "    'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y' , 'Zr',\n",
    "    'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn',\n",
    "    'Sb', 'Te', 'I' , 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd',\n",
    "    'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb',\n",
    "    'Lu', 'Hf', 'Ta', 'W' , 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
    "    'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th',\n",
    "    'Pa', 'U' , 'Np', 'Pu'] \n",
    "hardness = [\n",
    "0.47259288,\n",
    "0.92203391,\n",
    "0.17452888,\n",
    "0.25700733,\n",
    "0.33949086,\n",
    "0.42195412,\n",
    "0.50438193,\n",
    "0.58691863,\n",
    "0.66931351,\n",
    "0.75191607,\n",
    "0.17964105,\n",
    "0.22157276,\n",
    "0.26348578,\n",
    "0.30539645,\n",
    "0.34734014,\n",
    "0.38924725,\n",
    "0.43115670,\n",
    "0.47308269,\n",
    "0.17105469,\n",
    "0.20276244,\n",
    "0.21007322,\n",
    "0.21739647,\n",
    "0.22471039,\n",
    "0.23201501,\n",
    "0.23933969,\n",
    "0.24665638,\n",
    "0.25398255,\n",
    "0.26128863,\n",
    "0.26859476,\n",
    "0.27592565,\n",
    "0.30762999,\n",
    "0.33931580,\n",
    "0.37235985,\n",
    "0.40273549,\n",
    "0.43445776,\n",
    "0.46611708,\n",
    "0.15585079,\n",
    "0.18649324,\n",
    "0.19356210,\n",
    "0.20063311,\n",
    "0.20770522,\n",
    "0.21477254,\n",
    "0.22184614,\n",
    "0.22891872,\n",
    "0.23598621,\n",
    "0.24305612,\n",
    "0.25013018,\n",
    "0.25719937,\n",
    "0.28784780,\n",
    "0.31848673,\n",
    "0.34912431,\n",
    "0.37976593,\n",
    "0.41040808,\n",
    "0.44105777,\n",
    "0.05019332,\n",
    "0.06762570,\n",
    "0.08504445,\n",
    "0.10247736,\n",
    "0.11991105,\n",
    "0.13732772,\n",
    "0.15476297,\n",
    "0.17218265,\n",
    "0.18961288,\n",
    "0.20704760,\n",
    "0.22446752,\n",
    "0.24189645,\n",
    "0.25932503,\n",
    "0.27676094,\n",
    "0.29418231,\n",
    "0.31159587,\n",
    "0.32902274,\n",
    "0.34592298,\n",
    "0.36388048,\n",
    "0.38130586,\n",
    "0.39877476,\n",
    "0.41614298,\n",
    "0.43364510,\n",
    "0.45104014,\n",
    "0.46848986,\n",
    "0.48584550,\n",
    "0.12526730,\n",
    "0.14268677,\n",
    "0.16011615,\n",
    "0.17755889,\n",
    "0.19497557,\n",
    "0.21240778,\n",
    "0.07263525,\n",
    "0.09422158,\n",
    "0.09920295,\n",
    "0.10418621,\n",
    "0.14235633,\n",
    "0.16394294,\n",
    "0.18551941,\n",
    "0.22370139]\n",
    "#in Hartree\n",
    "HARDNESS = dict(zip(elements,hardness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyscf.gto.mole.Mole at 0x7ffc39a17490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = gto.Mole()\n",
    "mol.build(atom = '\\\n",
    "C         -4.89126        3.29770        0.00029;\\\n",
    "O         -3.49307        3.28429       -0.00328;\\\n",
    "H         -5.28213        2.58374        0.75736;\\\n",
    "H         -5.28213        3.05494       -1.01161;\\\n",
    "H         -5.23998        4.31540        0.27138;\\\n",
    "H         -3.22959        2.35981       -0.24953',\\\n",
    "basis = 'def2-SVP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = '\\\n",
    "# C         -3.15617        2.59898        0.79547;\\\n",
    "# C         -1.79169        2.11570        0.42917;\\\n",
    "# O         -0.80893        2.56621        0.99508;\\\n",
    "# H         -1.66947        1.36193       -0.34183;\\\n",
    "# H         -3.35300        2.38970        1.86780;\\\n",
    "# H         -3.91803        2.07820        0.17854;\\\n",
    "# H         -3.22824        3.69190        0.61449',\\\n",
    "# basis = 'def2-SVP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = 'O         -4.89126        3.29770        0.00029;\\\n",
    "# H         -3.49307        3.28429       -0.00328;\\\n",
    "# H         -5.28213        2.58374        0.75736', basis = 'def2-SVP', symmetry = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol = gto.Mole()\n",
    "# mol.build(atom = '\\\n",
    "# C         -1.44673        2.80824       -0.07813;\\\n",
    "# O         -1.78998        3.80792       -0.69188;\\\n",
    "# N         -1.18291        1.66325       -0.74926;\\\n",
    "# N         -1.33221        2.85136        1.26946;\\\n",
    "# H         -1.53168        3.72026        1.78651;\\\n",
    "# H         -1.04365        2.01512        1.79805;\\\n",
    "# H         -1.26824        1.62382       -1.77554;\\\n",
    "# H         -0.89270        0.81388       -0.24298'\\\n",
    "# , basis = 'def2-SVP', symmetry = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf = dft.RKS(mol) \n",
    "# mf.conv_tol = 1e-12\n",
    "# mf.grids.level = 9     # 0-9, big number for large mesh grids, default is 3\n",
    "# mf.xc = 'b3lyp'\n",
    "# mf.kernel()  #single point energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf = dft.RKS(mol) \n",
    "# mf.conv_tol = 1e-12\n",
    "# mf.grids.level = 9     # 0-9, big number for large mesh grids, default is 3\n",
    "# mf.xc = 'cam-b3lyp'\n",
    "# mf.kernel()  #single point energy\n",
    "\n",
    "#ORCA: FINAL SINGLE POINT ENERGY = -115.576160742154\n",
    "#Turbomole: total energy      =    -115.57615989622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -114.950987102225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-114.95098710222453"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = scf.RHF(mol) \n",
    "mf.conv_tol = 1e-13\n",
    "mf.kernel()  #single point energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIS = pyscf.tdscf.rhf.CIS(mf)\n",
    "# CIS.nstates = 5\n",
    "# CIS.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = tddft.TDA(mf)\n",
    "# start = time.time()\n",
    "# td.kernel()    #compute first few excited states.\n",
    "# end = time.time()\n",
    "# print ('Pyscf time =', round(end-start,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf.analyze()\n",
    "##MO energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf.mulliken_pop_meta_lowdin_ao()\n",
    "#population analysis\n",
    "#mf.mulliken_pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether a is symmetric\n",
    "# def check_symmetric(a, tol=1e-12):\n",
    "#     return np.all(np.abs(a-a.T) < tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_power (S,a):\n",
    "    s,ket = np.linalg.eigh(S)\n",
    "    # S = mf.get_ovlp() #.get_ovlp() is basis overlap matrix\n",
    "    # S = np.dot(np.linalg.inv(c.T), np.linalg.inv(c))\n",
    "    # #s are eigenvalues, must be all positive\n",
    "    # #each column of ket is a eigenket\n",
    "    s = s**a\n",
    "    X = np.linalg.multi_dot([ket,np.diag(s),ket.T])\n",
    "    #X == S^1/2\n",
    "    return X\n",
    "\n",
    "def orthonormalize (C):\n",
    "    X = matrix_power(mf.get_ovlp(), 0.5)\n",
    "    # X = S^1/2\n",
    "    C = np.dot(X,C)\n",
    "    return C\n",
    "# C is orthonormalized coefficient matrix\n",
    "# np.dot(C.T,C) is a identity matrix\n",
    "\n",
    "def coefficient_matrix ():\n",
    "    C = mf.mo_coeff\n",
    "    # mf.mo_coeff is the coefficient matrix\n",
    "    C = orthonormalize (C)\n",
    "    return C\n",
    "# rthogonalized MO coefficients \n",
    "C = coefficient_matrix ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Natm = mol.natm\n",
    "MOe = mf.mo_energy  \n",
    "#an array of MO energies, in Hartree\n",
    "\n",
    "occupied = len(np.where(mf.mo_occ > 0)[0])\n",
    "#mf.mo_occ is an array of occupance [2,2,2,2,2,0,0,0,0.....]\n",
    "virtual = len(np.where(mf.mo_occ == 0)[0])\n",
    "\n",
    "AO = [int(i.split(' ',1)[0]) for i in mol.ao_labels()] \n",
    "# .split(' ',1) is to split each element by space, split once.\n",
    "# mol.ao_labels() it is Labels of AO basis functions, AO is a list of corresponding atom_id\n",
    "# AO == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
    "N_bf = len(AO)\n",
    "\n",
    "a_x = 0.38\n",
    "beta1= 1.86\n",
    "beta2=0\n",
    "alpha1= 0.9\n",
    "alpha2=0\n",
    "beta = beta1 + beta2 * a_x\n",
    "alpha = alpha1 + alpha2 * a_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build gammaJ and gammaK matrix\n",
    "\n",
    "#function to return chemical hardness from dictionary HARDNESS\n",
    "def Hardness (atom_id):\n",
    "    atom = mol.atom_pure_symbol(atom_id) \n",
    "    return HARDNESS[atom]\n",
    "# mol.atom_pure_symbol(atom_id) returns pure element symbol, no special characters\n",
    "def eta (atom_A_id, atom_B_id):\n",
    "    eta = (Hardness(atom_A_id) + Hardness(atom_B_id))/2\n",
    "    return eta\n",
    "R = pyscf.gto.mole.inter_distance(mol, coords=None) \n",
    "#Inter-particle distance array\n",
    "# unit == ’Bohr’, Its value is 5.29177210903(80)×10^(−11) m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "GammaJ = np.zeros([Natm, Natm])\n",
    "for i in range (0, Natm):\n",
    "    for j in range (0, Natm):\n",
    "        GammaJ[i,j] = (R[i, j]**beta + (a_x * eta(i, j))**(-beta))**(-1/beta)\n",
    "\n",
    "GammaK = np.zeros([Natm, Natm])\n",
    "for i in range (0, Natm):\n",
    "    for j in range (0, Natm):\n",
    "        GammaK[i,j] = (R[i, j]**alpha + eta(i, j)**(-alpha)) **(-1/alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Natm = mol.natm \n",
    "def generateQ ():\n",
    "    q = np.zeros([Natm, N_bf, N_bf])\n",
    "    #N_bf is number Atomic orbitals, occupied+virtual, q is same size with C\n",
    "    C = coefficient_matrix ()\n",
    "    for atom_id in range (0, Natm):\n",
    "        for i in range (0, N_bf):\n",
    "            for p in range (0, N_bf):\n",
    "                for mu in range (0, N_bf):\n",
    "                    if AO[mu] == atom_id:\n",
    "                        #collect all basis functions centered on atom_id\n",
    "                        # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "                        q[atom_id,i,p] += C[mu,i]*C[mu,p]\n",
    "                        #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_tensorQ_gamma_tensors_building_time = 0.15026593208312988\n"
     ]
    }
   ],
   "source": [
    "q_tensors   = generateQ    ()\n",
    "q_tensor_ij = q_tensors [:, :occupied,:occupied]\n",
    "q_tensor_ab = q_tensors [:, occupied:,occupied:]\n",
    "q_tensor_ia = q_tensors [:, :occupied,occupied:]\n",
    "\n",
    "Q_K = np.einsum('Bjb, AB -> Ajb', q_tensor_ia, GammaK)\n",
    "Q_J = np.einsum('Bab, AB -> Aab', q_tensor_ab, GammaJ)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "Q_gamma_tensors_building_time = end - start\n",
    "print ('Q_tensorQ_gamma_tensors_building_time =', Q_gamma_tensors_building_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iajb_v = np.einsum('Aia, Bjb, AB, jbm -> iam', q_tensor_ia, q_tensor_ia, GammaK, V)\n",
    "\n",
    "# ijab_v = np.einsum('Aij, Bab, AB, jbm -> iam', q_tensor_ij, q_tensor_ab, GammaJ, V)\n",
    "# ijab_v = np.einsum('Aij, Aab, jbm -> iam', q_tensor_ij, Q_J,  V)\n",
    "\n",
    "def iajb_fly (V):\n",
    "    V = V.reshape(occupied, virtual, -1)\n",
    "    Q_K_V = np.einsum('Ajb, jbm -> Am', Q_K, V)\n",
    "    iajb_V = np.einsum('Aia, Am -> iam', q_tensor_ia, Q_K_V).reshape(occupied*virtual, -1)\n",
    "#     print('iajb done')\n",
    "    return iajb_V\n",
    "\n",
    "def ijab_fly (V):\n",
    "    V = V.reshape(occupied, virtual, -1)\n",
    "#     ijab_v = np.einsum('Aij, Aab, jbm -> iam', q_tensor_ij, Q_J,  V)\n",
    "\n",
    "    Aij_V = np.einsum('Aij, jbm -> Aibm', q_tensor_ij, V)\n",
    "    ijab_V = np.einsum('Aab, Aibm -> iam', Q_J, Aij_V).reshape(occupied*virtual, -1)\n",
    "\n",
    "#     print ('ijab done')\n",
    "#     Aab_V = np.einsum('Aab, jbm -> jAam', Q_J, V)\n",
    "#     ijab_V = np.einsum('Aij, jAam -> iam', q_tensor_ij, Aab_V).reshape(occupied*virtual, -1)\n",
    "    return ijab_V\n",
    "\n",
    "delta_diag_A = np.zeros((occupied, virtual))\n",
    "for i in range (0, occupied):\n",
    "    for a in range (0, virtual):\n",
    "        delta_diag_A[i,a] = (MOe[occupied+a] - MOe[i])\n",
    "\n",
    "# delta_ij = np.eye(occupied,occupied)\n",
    "# delta_ab = np.eye(virtual,virtual)\n",
    "def delta_fly (V):\n",
    "    V = V.reshape(occupied, virtual, -1)\n",
    "#     print ('Shape of V = ', np.shape(V))\n",
    "    #delta_v = np.einsum('ij,ab,ia,jb -> ia',delta_ij,delta_ab,delta_diag_A, v)\n",
    "    delta_v = np.einsum('ia,iam -> iam', delta_diag_A, V).reshape(occupied*virtual, -1)\n",
    "    return delta_v\n",
    "\n",
    "def sTDA_fly (V):\n",
    "    V = V.reshape(occupied*virtual,-1)\n",
    "    # -1 means shape of first dimension is not asigned, but can be inferred with the rest dimension\n",
    "    # this feature can deal with multiple vectors\n",
    "    sTDA_V =  delta_fly (V) + 2*iajb_fly (V) - ijab_fly (V) \n",
    "#     sTDA_V = sTDA_V.reshape(occupied*virtual, -1)\n",
    "#     print (np.shape(sTDA_v))\n",
    "    return sTDA_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_tensorQ_gamma_tensors_building_time = 0.15026593208312988\n",
      "sTDA_A building time =  0.03017878532409668\n",
      "total building sTDA A time = 0.2307589054107666\n",
      "[12.2388045  13.59944497 13.79151538 15.04073066]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = occupied * virtual\n",
    "I = np.eye(n)\n",
    "\n",
    "start = time.time()\n",
    "sTDA_A = sTDA_fly (I)\n",
    "end = time.time()  \n",
    "\n",
    "sTDA_A_building_time = end - start\n",
    "\n",
    "print ('Q_tensorQ_gamma_tensors_building_time =', Q_gamma_tensors_building_time)\n",
    "\n",
    "print ('sTDA_A building time = ', sTDA_A_building_time)\n",
    "\n",
    "total_end = time.time()  \n",
    "\n",
    "total_build_time = total_end - total_begin\n",
    "\n",
    "print ('total building sTDA A time =', total_build_time)\n",
    "\n",
    "s,k = np.linalg.eigh(sTDA_A)\n",
    "print (s[:4]*27.21138624598853)\n",
    "\n",
    "\n",
    "# ijab contract ij first \n",
    "# Q_tensorQ_gamma_tensors_building_time = 0.14207124710083008\n",
    "# sTDA_A building time =  0.03429985046386719\n",
    "# sTDA_A building time =  0.031857967376708984\n",
    "# sTDA_A building time =  0.03574705123901367\n",
    "# sTDA_A building time =  0.03632998466491699\n",
    "# sTDA_A building time =  0.03199195861816406\n",
    "# total building sTDA A time = 0.21783995628356934\n",
    "# [12.2388045  13.59944497 13.79151538 15.04073066]\n",
    "\n",
    "\n",
    "# ijab contract ab first\n",
    "# Q_tensorQ_gamma_tensors_building_time = 0.1520397663116455\n",
    "# sTDA_A building time =  0.03174281120300293\n",
    "# sTDA_A building time =  0.03430318832397461\n",
    "# sTDA_A building time =  0.029811859130859375\n",
    "# sTDA_A building time =  0.03499102592468262\n",
    "# sTDA_A building time =  0.033949851989746094\n",
    "# sTDA_A building time =  0.035989999771118164\n",
    "# sTDA_A building time =  0.03299880027770996\n",
    "# total building sTDA A time = 0.2343301773071289\n",
    "# [12.2388045  13.59944497 13.79151538 15.04073066]\n",
    "\n",
    "\n",
    "\n",
    "plt.matshow(sTDA_A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # suppose a has N columns\n",
    "# #a[:, :n] means the first n columns\n",
    "# #a[:, n:] means \"except\" the first n columns\n",
    "\n",
    "# #a[:, -n:] means the last n columns\n",
    "# #a[:, :-n] means the firts (N-n) columns, or \"except\" the last n columns\n",
    "\n",
    "# #a[:, n:m] measn from index(n) column to index(m-1) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,2):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def orthonormalize (v1, v2):\n",
    "# #     v1 = v1/np.linalg.norm(v1)\n",
    "#     v2 = v2 - (np.dot(v1, v2) / np.dot(v1, v1)) * v1\n",
    "# #     v2 = v2 - np.dot(v1, v2) * v1\n",
    "#     v2 = v2/np.linalg.norm(v2)\n",
    "#     return v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = np.random.rand(10,5)\n",
    "# print (Q)\n",
    "# #built-in function of np approaching, V is the a orthonnormalized matrix\n",
    "# V,R = np.linalg.qr(Q)\n",
    "# print (V)\n",
    "# print (np.dot(V.T, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = Gram_Schdmit (Q)\n",
    "# print (Q)\n",
    "# print (np.dot(Q.T, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gram_Schdmit_bvec (A, bvec):\n",
    "    # suppose A is orthonormalized\n",
    "    projections = np.dot(A.T, bvec)\n",
    "    bvec = bvec - np.dot(A, projections)   \n",
    "    bvec = bvec/np.linalg.norm(bvec)\n",
    "    return bvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gram_Schdmit (A):\n",
    "    # A matrix has J columns, orthonormalize each columns\n",
    "    N_vectors = np.shape(A)[1]\n",
    "    \n",
    "    A = A/np.linalg.norm(A, axis=0, keepdims = True)\n",
    "    \n",
    "#     for p in range (0, J - 1):\n",
    "#         for q in range (p + 1, J):\n",
    "#             A[:, q] = orthonormalize(A[:, p], A[:, q])\n",
    "    \n",
    "    for j in range (1, N_vectors):\n",
    "        A[:, j] = Gram_Schdmit_bvec (A[:, :j], A[:, j])\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gram_Schdmit_append (A, B):\n",
    "    # A_I*P, B_I*Q\n",
    "    # suppose A is already orthonormalized\n",
    "    # append B to A, and orthonormalize matrix B against A, \n",
    "    \n",
    "    A_vectors = np.shape(A)[1]\n",
    "    B_vectors = np.shape(B)[1]\n",
    "    \n",
    "    C = np.append (A, B, axis=1)\n",
    "    \n",
    "    for j in range (0, B_vectors):\n",
    "        bvec = B[:,j]\n",
    "        bvec = Gram_Schdmit_bvec (C[:, :A_vectors + j], B[:,j])\n",
    "        C[:, A_vectors + j] = bvec\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gram_Schdmit_against (A, B):\n",
    "    # suppose A is already orthonormalized\n",
    "    # orthonormalize vectors in B against A, as well as B it self\n",
    "    B = Gram_Schdmit (B)\n",
    "    \n",
    "    A_vectors = np.shape(A)[1]\n",
    "    B_vectors = np.shape(B)[1]\n",
    "    \n",
    "    for j in range (0, B_vectors):\n",
    "        B[:,j] = Gram_Schdmit_bvec (A, B[:,j])\n",
    "    \n",
    "    B = Gram_Schdmit (B)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_orthonormal (A):\n",
    "    n = np.shape(A)[1]\n",
    "    B = np.dot (A.T, A)\n",
    "    c = np.linalg.norm(B - np.eye(n))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random ((600,120))\n",
    "A = Gram_Schdmit (a)\n",
    "\n",
    "b = np.random.random ((600,140))\n",
    "x = np.random.random ((600,140))\n",
    "z = np.random.random ((600,14))\n",
    "\n",
    "dab = np.append (a,b, axis=1)\n",
    "dabx = np.append (dab, x, axis=1)\n",
    "dabxz = np.append (dabx, z, axis=1)\n",
    "\n",
    "cab = Gram_Schdmit_append (A, b)\n",
    "cabx = Gram_Schdmit_append (cab, x)\n",
    "cabxz = Gram_Schdmit_append (cabx, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append = 2.39627631125204e-13\n",
      "standard = 2.2438132086519092e-13\n",
      "norm of difference = 2.0494147891074038e-13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('append =', check_orthonormal(cabxz))\n",
    "\n",
    "\n",
    "e = Gram_Schdmit (dabxz)\n",
    "print ('standard =', check_orthonormal(e))\n",
    "\n",
    "print ('norm of difference =', np.linalg.norm(cabxz-e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8869680334528384e-14\n",
      "1.2541294146927256e-14\n",
      "6.323648811429247e-14\n"
     ]
    }
   ],
   "source": [
    "g = Gram_Schdmit_against (A, x)\n",
    "print (check_orthonormal (A))\n",
    "print (check_orthonormal (g))\n",
    "print (check_orthonormal (np.append(A, g, axis =1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holder (V, W, vcount, vecs):\n",
    "    # holder is an zero matrix\n",
    "    # count is the amount of vectors that already sit in the holder\n",
    "    nvec = np.shape(vecs)[1]\n",
    "    # amount of new vectors to fill in\n",
    "    \n",
    "    V[:, vcount: (vcount + nvec)] = vecs\n",
    "    W[:, vcount: (vcount + nvec)] = sTDA_fly(vecs)\n",
    "\n",
    "    vcount += nvec\n",
    "#     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "#     print ('norms of W =', np.linalg.norm(W, axis=0, keepdims = True))\n",
    "    return V, W, vcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros ((351,50))\n",
    "b = np.zeros ((351,50))\n",
    "x = np.random.random ((351, 5))\n",
    "x = Gram_Schdmit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0239461948992617e-15\n",
      "0.0\n",
      "norms of a = [[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a, b, c = fill_holder (a, b, 0, x)\n",
    "print (check_orthonormal(a[:, :c]))\n",
    "print (np.linalg.norm(a[:, :c] - x))\n",
    "print ('norms of a =', np.linalg.norm(a, axis=0, keepdims = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "def preconditioner_sTDA (B, eigen_lambda, Y=0): \n",
    "    Lambda = np.diag(eigen_lambda)\n",
    "    # (sTDA_A - eigen_lambda*I)^-1 B = X \n",
    "    # AX - X\\lambda = B\n",
    "\n",
    "    # columns of B are the vectors to be preconditioned, \n",
    "    N_rows = np.shape(B)[0]\n",
    "    \n",
    "    B = B.reshape(N_rows, -1)\n",
    "\n",
    "    N_vectors = np.shape(B)[1]\n",
    "    #number of vectors to be preconditioned\n",
    "    \n",
    "    bnorm = np.linalg.norm(B, axis=0, keepdims = True)\n",
    "    #norm of each vectors in B, shape (1,-1)\n",
    "    B = B/bnorm\n",
    "#     print ('shape of B=', np.shape(B))\n",
    "    start = time.time()\n",
    "    tol = 1e-5     # Convergence tolerance\n",
    "    max = 30    # Maximum number of iterations  \n",
    "    \n",
    "    V = np.zeros((N_rows, max*N_vectors))\n",
    "    W = np.zeros((N_rows, max*N_vectors))\n",
    "    count = 0\n",
    "#     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "    # now V and W are empty holders, 0 vectors\n",
    "    # W = sTDA_fly(V)\n",
    "    # count is the amount of vectors that already sit in the holder\n",
    "    # at the end of each iteration, V and W will be filled/updated with new guess vectors\n",
    "    \n",
    "    ###########################################\n",
    "    #initial guess: (diag(A) - \\lambda)^-1 B.\n",
    "    diag = delta_diag_A.flatten()\n",
    "#     # delta_diag_A.flatten() is (\\spsilon_a-\\spsilon_i)\n",
    "\n",
    "    D = np.zeros((N_rows, N_vectors))\n",
    "    for i in range (0, N_vectors):\n",
    "        D[:,i] = diag - eigen_lambda[i]\n",
    "\n",
    "    #D is preconditioner for each state \n",
    "#     print ('shape of D =', np.shape(D))\n",
    "    \n",
    "    init = B/D\n",
    "#     print ('check init0', check_orthonormal(init))\n",
    "    init = Gram_Schdmit(init)\n",
    "#     print ('norm of init = ', np.linalg.norm (init))\n",
    "#     print ('check init1', check_orthonormal(init))\n",
    "#     print ('shape of init =', np.shape(init))\n",
    "#     print ('check V0', check_orthonormal(V))\n",
    "    ###########################################\n",
    "\n",
    "    V, W, count = fill_holder (V, W, count, init)\n",
    "#     print ('norms of V =', np.linalg.norm(V, axis=0, keepdims = True))\n",
    "#     print ('check V0', check_orthonormal(V[:,:count]))\n",
    "#     print ('norm of first vec',np.linalg.norm(V[:,:count]))\n",
    "#     print ('count = ',count)\n",
    "    # initial guess settled \n",
    "\n",
    "    ####################################################################################\n",
    "    # Begin iterations\n",
    "    for i in range (0, max):\n",
    "#         print ('Iteration =', i)\n",
    "        sub_B = np.dot(V[:,:count].T, B) \n",
    "        sub_A = np.dot(V[:,:count].T, W[:,:count])    \n",
    "        #project sTDA_A matrix and vector B into subspace \n",
    "        m = np.shape(sub_A)[0]\n",
    "#         print ('subaspace size = ', np.shape(sub_A))\n",
    "#         print ('check V1', check_orthonormal(V[:,:count]))\n",
    "        #m is always the size of subspace\n",
    "#         print ('Size of subspace =', m)\n",
    "        # size of subspace\n",
    "        sub_guess = scipy.linalg.solve_sylvester(sub_A, - Lambda, sub_B)   \n",
    "        #scipy.linalg.solve_sylvester(A,B,Q) # solve equation AX + XB = Q\n",
    "#         print ('shape of sub_guess = ', np.shape(sub_guess))\n",
    "#         print ('shape of V = ', np.shape(V))\n",
    "#         sub_guess = Gram_Schdmit(sub_guess)\n",
    "        full_guess = np.dot(V[:,:count], sub_guess)\n",
    "#         print ('shape of full_guess = ', np.shape(full_guess))\n",
    "#         print ('shape of sTDA_fly(full_guess) = ', np.shape(sTDA_fly(full_guess)))\n",
    "#         print ('shape of eigen_lambda * full_guess = ', np.shape(eigen_lambda * full_guess))       \n",
    "        \n",
    "        residual = np.dot(W[:,:count], sub_guess) - full_guess*eigen_lambda - B  \n",
    "        \n",
    "#         print ('shape of residual rrrrrrr= ', np.shape(residual))   \n",
    "        Norms_of_r = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "#         print ('Norms_of_r =', Norms_of_r)\n",
    "\n",
    "#         print ('shape of Norm =', np.shape(Norms_of_r))\n",
    "        \n",
    "        max_norm = np.max(Norms_of_r)\n",
    "        \n",
    "#         print ('max_norm = ', max_norm)\n",
    "        if max_norm < tol:\n",
    "            break\n",
    "        index = [i for i in range(np.shape(Norms_of_r)[1]) if Norms_of_r[0,i] > tol]\n",
    "        # index for not converged residuals\n",
    "#         print ('index =',index)\n",
    "\n",
    "#         print ('shape of residaul =', np.shape(residual))\n",
    "        \n",
    "        # preconditioning step\n",
    "        # only generate new guess from unconverged residuals\n",
    "        new_guess = residual[:,index]/D[:,index]\n",
    "#         print ('shape of new_guess =', np.shape(new_guess))\n",
    "        \n",
    "#         new_guess = Gram_Schdmit (Gram_Schdmit)\n",
    "        new_guess = Gram_Schdmit_against (V[:,:count], new_guess)\n",
    "#         print ('shape of new_guess0 =', np.shape(new_guess))\n",
    "#         print ('check new_guess', check_orthonormal(new_guess))\n",
    "#       \n",
    "#         V = Gram_Schdmit_append(V, new_guess)\n",
    "#         V = np.append(V, new_guess, axis = 1)\n",
    "#         V = Gram_Schdmit(V)\n",
    "       \n",
    "        \n",
    "#         print ('count1 = ',count)\n",
    "        V, W, count = fill_holder (V, W, count, new_guess)\n",
    "#         print ('count2 = ',count)\n",
    "        if i%10 == 0 and i!= 0:\n",
    "            V[:,:count] = Gram_Schdmit(V[:,:count])\n",
    "#         print ('check orthonormal of V', check_orthonormal(V[:,:count]))\n",
    "#         W = np.append(W, sTDA_fly(V[:, m:]), axis=1)\n",
    "#         W = sTDA_fly(V)\n",
    "        # add new guess to the guess space\n",
    "    ####################################################################################      \n",
    "\n",
    "    #########################################################################################\n",
    "    end = time.time()\n",
    "    print ('Iteration_steps =', i, ', Time:', round(end-start,4), 's')\n",
    "    \n",
    "#     ####del list[n]\n",
    "# # A = np.delete(A, n, axis=1)\n",
    "    print ('Size of subspace =', m)\n",
    "    return (full_guess*bnorm)\n",
    "#     return (full_guess)\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_residuals =  1\n",
      "Iteration_steps = 3 , Time: 0.0035 s\n",
      "Size of subspace = 4\n",
      "Norm of normalized difference:  7.983706565683984e-06\n",
      "n_residuals =  3\n",
      "Iteration_steps = 17 , Time: 0.0193 s\n",
      "Size of subspace = 30\n",
      "Norm of normalized difference:  1.9596443529030173e-07\n",
      "n_residuals =  5\n",
      "Iteration_steps = 14 , Time: 0.0297 s\n",
      "Size of subspace = 57\n",
      "Norm of normalized difference:  3.624252374767067e-08\n",
      "n_residuals =  7\n",
      "Iteration_steps = 15 , Time: 0.0339 s\n",
      "Size of subspace = 66\n",
      "Norm of normalized difference:  2.0696771820090192e-08\n",
      "n_residuals =  9\n",
      "Iteration_steps = 13 , Time: 0.0396 s\n",
      "Size of subspace = 75\n",
      "Norm of normalized difference:  9.723558285736775e-08\n",
      "n_residuals =  11\n",
      "Iteration_steps = 14 , Time: 0.0518 s\n",
      "Size of subspace = 87\n",
      "Norm of normalized difference:  1.3204318469341936e-07\n",
      "n_residuals =  13\n",
      "Iteration_steps = 14 , Time: 0.0811 s\n",
      "Size of subspace = 113\n",
      "Norm of normalized difference:  9.069797578097823e-08\n",
      "n_residuals =  15\n",
      "Iteration_steps = 11 , Time: 0.0808 s\n",
      "Size of subspace = 122\n",
      "Norm of normalized difference:  1.8146822655147213e-06\n",
      "n_residuals =  17\n",
      "Iteration_steps = 11 , Time: 0.0859 s\n",
      "Size of subspace = 120\n",
      "Norm of normalized difference:  1.8653654639263877e-08\n",
      "n_residuals =  19\n",
      "Iteration_steps = 11 , Time: 0.0865 s\n",
      "Size of subspace = 126\n",
      "Norm of normalized difference:  1.7949172577413418e-07\n"
     ]
    }
   ],
   "source": [
    "for n_residuals in range (1,20,2):\n",
    "    \n",
    "    B = np.random.random ((occupied*virtual, n_residuals))\n",
    "\n",
    "    Y = None\n",
    "\n",
    "    eigen_lambda = np.arange(10, 10+n_residuals)\n",
    "\n",
    "    print ('n_residuals = ',n_residuals)\n",
    "\n",
    "    preconditioned_B =  preconditioner_sTDA (B, eigen_lambda, Y)\n",
    "    # print ('Norm of preconditioned_B', np.linalg.norm(preconditioned_B))\n",
    "    true_answer = scipy.linalg.solve_sylvester(sTDA_A, -np.diag(eigen_lambda), B)\n",
    "\n",
    "    # print ('Norm of true_answer     ',np.linalg.norm(true_answer))\n",
    "    # print (np.shape(true_answer))\n",
    "\n",
    "#     print ('Norm of difference: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "    # print (np.shape(true_answer - preconditioned_B))\n",
    "\n",
    "    preconditioned_B = preconditioned_B/np.linalg.norm(preconditioned_B)\n",
    "    true_answer = true_answer/np.linalg.norm(true_answer)\n",
    "    print ('Norm of normalized difference: ', np.linalg.norm(true_answer - preconditioned_B))\n",
    "\n",
    "# residual size: 351\n",
    "# convergence threshold = 1e-5\n",
    "\n",
    "\n",
    "\n",
    "# n_residuals =  1\n",
    "# Iteration_steps = 3 , Time: 0.0036 s\n",
    "# n_residuals =  2\n",
    "# Iteration_steps = 7 , Time: 0.0148 s\n",
    "# n_residuals =  3\n",
    "# Iteration_steps = 16 , Time: 0.0467 s\n",
    "# n_residuals =  4\n",
    "# Iteration_steps = 15 , Time: 0.0523 s\n",
    "# n_residuals =  5\n",
    "# Iteration_steps = 14 , Time: 0.0528 s\n",
    "# n_residuals =  6\n",
    "# Iteration_steps = 13 , Time: 0.0597 s\n",
    "# n_residuals =  7\n",
    "# Iteration_steps = 12 , Time: 0.0569 s\n",
    "# n_residuals =  8\n",
    "# Iteration_steps = 12 , Time: 0.0794 s\n",
    "# n_residuals =  9\n",
    "# Iteration_steps = 12 , Time: 0.1018 s\n",
    "\n",
    "\n",
    "\n",
    "# n_residuals =  1\n",
    "# Iteration_steps = 3 , Time: 0.0037 s\n",
    "# n_residuals =  2\n",
    "# Iteration_steps = 5 , Time: 0.0102 s\n",
    "# n_residuals =  3\n",
    "# Iteration_steps = 17 , Time: 0.0324 s\n",
    "# n_residuals =  4\n",
    "# Iteration_steps = 16 , Time: 0.0495 s\n",
    "# n_residuals =  5\n",
    "# Iteration_steps = 14 , Time: 0.0494 s\n",
    "# n_residuals =  6\n",
    "# Iteration_steps = 13 , Time: 0.0499 s\n",
    "# n_residuals =  7\n",
    "# Iteration_steps = 13 , Time: 0.0596 s\n",
    "# n_residuals =  8\n",
    "# Iteration_steps = 13 , Time: 0.057 s\n",
    "# n_residuals =  9\n",
    "# Iteration_steps = 14 , Time: 0.0722 s\n",
    "\n",
    "\n",
    "# n_residuals =  1\n",
    "# Iteration_steps = 4 , Time: 0.0047 s\n",
    "# Size of subspace = 5\n",
    "# n_residuals =  2\n",
    "# Iteration_steps = 6 , Time: 0.008 s\n",
    "# Size of subspace = 12\n",
    "# n_residuals =  3\n",
    "# Iteration_steps = 17 , Time: 0.0227 s\n",
    "# Size of subspace = 30\n",
    "# n_residuals =  4\n",
    "# Iteration_steps = 17 , Time: 0.0246 s\n",
    "# Size of subspace = 45\n",
    "# n_residuals =  5\n",
    "# Iteration_steps = 16 , Time: 0.0345 s\n",
    "# Size of subspace = 56\n",
    "# n_residuals =  6\n",
    "# Iteration_steps = 14 , Time: 0.0269 s\n",
    "# Size of subspace = 61\n",
    "# n_residuals =  7\n",
    "# Iteration_steps = 24 , Time: 0.094 s\n",
    "# Size of subspace = 122\n",
    "# n_residuals =  8\n",
    "# Iteration_steps = 24 , Time: 0.1034 s\n",
    "# Size of subspace = 146\n",
    "# n_residuals =  9\n",
    "# Iteration_steps = 14 , Time: 0.0361 s\n",
    "# Size of subspace = 74\n",
    "#\n",
    "\n",
    "# use 5 ranodm orthogonal initial guess\n",
    "# n_residuals =  1\n",
    "# Iteration_steps = 4 , Time: 0.0064 s\n",
    "# Size of subspace = 9\n",
    "# n_residuals =  2\n",
    "# Iteration_steps = 8 , Time: 0.0115 s\n",
    "# Size of subspace = 18\n",
    "# n_residuals =  3\n",
    "# Iteration_steps = 19 , Time: 0.0239 s\n",
    "# Size of subspace = 35\n",
    "# n_residuals =  4\n",
    "# Iteration_steps = 17 , Time: 0.0297 s\n",
    "# Size of subspace = 50\n",
    "# n_residuals =  5\n",
    "# Iteration_steps = 16 , Time: 0.0366 s\n",
    "# Size of subspace = 63\n",
    "# n_residuals =  6\n",
    "# Iteration_steps = 14 , Time: 0.0266 s\n",
    "# Size of subspace = 67\n",
    "# n_residuals =  7\n",
    "# Iteration_steps = 15 , Time: 0.0319 s\n",
    "# Size of subspace = 71\n",
    "# n_residuals =  8\n",
    "# Iteration_steps = 14 , Time: 0.0361 s\n",
    "# Size of subspace = 76\n",
    "# n_residuals =  9\n",
    "# Iteration_steps = 14 , Time: 0.0385 s\n",
    "# Size of subspace = 80\n",
    "\n",
    "# n_residuals =  1\n",
    "# Iteration_steps = 3 , Time: 0.0035 s\n",
    "# Size of subspace = 4\n",
    "# Norm of normalized difference:  7.983706565683984e-06\n",
    "# n_residuals =  3\n",
    "# Iteration_steps = 17 , Time: 0.0193 s\n",
    "# Size of subspace = 30\n",
    "# Norm of normalized difference:  1.9596443529030173e-07\n",
    "# n_residuals =  5\n",
    "# Iteration_steps = 14 , Time: 0.0297 s\n",
    "# Size of subspace = 57\n",
    "# Norm of normalized difference:  3.624252374767067e-08\n",
    "# n_residuals =  7\n",
    "# Iteration_steps = 15 , Time: 0.0339 s\n",
    "# Size of subspace = 66\n",
    "# Norm of normalized difference:  2.0696771820090192e-08\n",
    "# n_residuals =  9\n",
    "# Iteration_steps = 13 , Time: 0.0396 s\n",
    "# Size of subspace = 75\n",
    "# Norm of normalized difference:  9.723558285736775e-08\n",
    "# n_residuals =  11\n",
    "# Iteration_steps = 14 , Time: 0.0518 s\n",
    "# Size of subspace = 87\n",
    "# Norm of normalized difference:  1.3204318469341936e-07\n",
    "# n_residuals =  13\n",
    "# Iteration_steps = 14 , Time: 0.0811 s\n",
    "# Size of subspace = 113\n",
    "# Norm of normalized difference:  9.069797578097823e-08\n",
    "# n_residuals =  15\n",
    "# Iteration_steps = 11 , Time: 0.0808 s\n",
    "# Size of subspace = 122\n",
    "# Norm of normalized difference:  1.8146822655147213e-06\n",
    "# n_residuals =  17\n",
    "# Iteration_steps = 11 , Time: 0.0859 s\n",
    "# Size of subspace = 120\n",
    "# Norm of normalized difference:  1.8653654639263877e-08\n",
    "# n_residuals =  19\n",
    "# Iteration_steps = 11 , Time: 0.0865 s\n",
    "# Size of subspace = 126\n",
    "# Norm of normalized difference:  1.7949172577413418e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "def preconditioner_sTDA (B, eigen_lambda, Y=0): \n",
    "    # (sTDA_A - eigen_lambda*I)^-1 B = X \n",
    "    # AX - X\\lambda = B\n",
    "\n",
    "    # columns of B are the vectors to be preconditioned, \n",
    "    n = np.shape(B)[0]\n",
    "    \n",
    "    B = B.reshape(n,-1)\n",
    "\n",
    "    N_vectors = np.shape(B)[1]\n",
    "    #number of vectors to be preconditioned\n",
    "    \n",
    "    bnorm = np.linalg.norm(B, axis=0, keepdims = True)\n",
    "    #norm of each vectors in B, shape (1,-1)\n",
    "    B = B/bnorm\n",
    "#     print ('shape of B=', np.shape(B))\n",
    "    start = time.time()\n",
    "    tol = 1e-5     # Convergence tolerance\n",
    "    max = 30      # Maximum number of iterations  \n",
    "    \n",
    "    diag = delta_diag_A.flatten()\n",
    "#     # delta_diag_A.flatten() is (\\spsilon_a-\\spsilon_i)\n",
    "\n",
    "    D = np.zeros([n,N_vectors])\n",
    "    for i in range (0, N_vectors):\n",
    "        D[:,i] = diag - eigen_lambda[i]\n",
    "#         D[:,i][(D[:,i]<1e-16)&(D[:,i]>=0)] = 1e-20\n",
    "#         D[:,i][(D[:,i]>-1e-16)&(D[:,i]<0)] = -1e-20\n",
    "    #D is preconditioner for each state \n",
    "    print ('shape of D =', np.shape(D))\n",
    "    ###########################################\n",
    "    #initial guess: (diag(A) - \\lambda)^-1 B.\n",
    "    V = B/D\n",
    "    V = Gram_Schdmit(V)\n",
    "    print ('shape of V =', np.shape(V))\n",
    "    \n",
    "    W = sTDA_fly(V) \n",
    "    #V is guess holder, \n",
    "    # at the end of each iteration, V will be appended with new guess vectors\n",
    "    \n",
    "    Lambda = np.diag(eigen_lambda)\n",
    "\n",
    "    ####################################################################################\n",
    "    # Begin iterations\n",
    "    for i in range (0, max):\n",
    "        print ('Iteration =', i)\n",
    "        sub_B = np.dot(V.T, B) \n",
    "        sub_A = np.dot(V.T, W)    \n",
    "        #project sTDA_A matrix and vector B into subspace \n",
    "        m = np.shape(sub_A)[0]\n",
    "        print ('subaspace size = ', np.shape(sub_A))\n",
    "        print ('check V', np.linalg.norm(np.dot(V.T, V)- np.eye(m)))\n",
    "        #m is always the size of subspace\n",
    "#         print ('Size of subspace =', m)\n",
    "        # size of subspace\n",
    "        sub_guess = scipy.linalg.solve_sylvester(sub_A, - Lambda, sub_B)   \n",
    "        #scipy.linalg.solve_sylvester(A,B,Q) # solve equation AX + XB = Q\n",
    "#         print ('shape of sub_guess = ', np.shape(sub_guess))\n",
    "#         print ('shape of V = ', np.shape(V))\n",
    "       \n",
    "        full_guess = np.dot(V, sub_guess)\n",
    "#         print ('shape of full_guess = ', np.shape(full_guess))\n",
    "#         print ('shape of sTDA_fly(full_guess) = ', np.shape(sTDA_fly(full_guess)))\n",
    "#         print ('shape of eigen_lambda * full_guess = ', np.shape(eigen_lambda * full_guess))       \n",
    "        \n",
    "        residual = sTDA_fly(full_guess) - full_guess*eigen_lambda - B  \n",
    "        \n",
    "#         print ('shape of residual rrrrrrr= ', np.shape(residual))   \n",
    "        Norms_of_residual = np.linalg.norm (residual, axis=0, keepdims = True)\n",
    "        print ('Norms_of_residual =', Norms_of_residual)\n",
    "\n",
    "#         print ('shape of Norm =', np.shape(Norms_of_residual))\n",
    "        \n",
    "        max_norm = np.max(Norms_of_residual)\n",
    "        \n",
    "        print ('max_norm = ', max_norm)\n",
    "        if max_norm < tol:\n",
    "            break\n",
    "#         index = np.where(max_norm < tol)\n",
    "#         D[:, index] = 1\n",
    "        guess = residual/D \n",
    "        #preconditioning step\n",
    "\n",
    "#         V = Gram_Schdmit_append(V, guess)\n",
    "        V = np.append(V, guess, axis = 1)\n",
    "        V = Gram_Schdmit(V)\n",
    "#         W = np.append(W, sTDA_fly(guess), axis=1)\n",
    "        W = sTDA_fly(V)\n",
    "        # add new guess to the guess space\n",
    "    ####################################################################################      \n",
    "\n",
    "    #########################################################################################\n",
    "#    print ('sTDA_Iteration steps =', i)\n",
    "    end = time.time()\n",
    "    print ('sTDA_Precondition time:', round(end-start,4))\n",
    "\n",
    "# del list[n]\n",
    "# A = np.delete(A, n, axis=1)\n",
    "\n",
    "    return (full_guess*bnorm)\n",
    "#     return (full_guess)\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = tddft.TDA(mf)\n",
    "vind, hdiag = td.gen_vind(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "def A_diag_initial_guess (k):\n",
    "    m = min([2*k, k+8, occupied*virtual])\n",
    "    # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "    # m=k works for H2, m=4k works for H2O\n",
    "    V = np.zeros((n, m)) \n",
    "    #array of zeros, a container to hold current guess vectors \n",
    "    W = np.zeros((n, m)) \n",
    "    \n",
    "    sort = hdiag.argsort()\n",
    "    for j in range(0,m):\n",
    "        V[int(np.argwhere(sort == j)), j] = 1   \n",
    "        # positions with lowest values set as 1\n",
    "        W[:, j] = vind(V[:, j])\n",
    "    # W = Av, create transformed guess vectors\n",
    "\n",
    "    return (m, V, W)\n",
    "\n",
    "def sTDA_initial_guess (k):\n",
    "    m = min([2*k, k+8, occupied*virtual])\n",
    "    # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "    # m=k works for H2, m=4k works for H2O\n",
    "    V = np.zeros((n, m)) \n",
    "    # array of zeros, a container to hold current guess vectors, v\n",
    "    W = np.zeros((n, m)) \n",
    "    # a container to hold transformed guess vectors, Av\n",
    "    eigvalues, eigkets = np.linalg.eigh(sTDA_A)\n",
    "    # eigv, eigk = Davidson (A, m, 1e-5, default_initial_guess, A_diag_preconditioner)\n",
    "    #!!!!!!!! diagonalize sTDA_A amtrix\n",
    "    for j in range(0,m):\n",
    "        V[:, j] = eigkets [:, j]\n",
    "        W[:, j] = vind(V[:, j])\n",
    "        \n",
    "    return (m, V, W)\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###################################################################\n",
    "def A_diag_preconditioner (residual, sub_eigenvalue):\n",
    "    d = hdiag - sub_eigenvalue\n",
    "    d[(d<1e-16)&(d>=0)] = 1e-16\n",
    "    d[(d>-1e-16)&(d<0)] = -1e-16   \n",
    "    #kick out all small values\n",
    "    \n",
    "    new_vec = residual/d\n",
    "    return new_vec\n",
    "\n",
    "def sTDA_preconditioner (residual, sub_eigenvalue):\n",
    "    new_vec = np.dot(np.linalg.inv(sTDA_A - sub_eigenvalue*I),residual)\n",
    "    return new_vec\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def Davidson (k, tol, initial_guess, preconditioner):\n",
    "\n",
    "    if initial_guess == 'sTDA_initial_guess':\n",
    "        initial_guess = sTDA_initial_guess\n",
    "        print ('Initial guess: sTDA A matrix')\n",
    "    elif initial_guess == 'A_diag_initial_guess':\n",
    "        initial_guess = A_diag_initial_guess\n",
    "        print ('Initial guess: Diagonal of Pseudo A matrix')\n",
    "        \n",
    "    if preconditioner == 'sTDA_fly_preconditioner':\n",
    "        preconditioner = preconditioner_sTDA\n",
    "        print ('Preconditioner: on-the-fly sTDA A matrix')\n",
    "        \n",
    "    elif preconditioner == 'full_sTDA_preconditioner':\n",
    "        preconditioner = sTDA_preconditioner\n",
    "        print ('Preconditioner: full sTDA A matrix')\n",
    "        \n",
    "    elif preconditioner == 'A_diag_preconditioner':\n",
    "        preconditioner = A_diag_preconditioner\n",
    "        print ('Preconditioner: Diagonal of Pseudo A matrix')\n",
    "    start = time.time()\n",
    "    \n",
    "    #tol = 1e-5      \n",
    "    # Convergence tolerance\n",
    "    n = occupied*virtual\n",
    "    max = 90      \n",
    "    # Maximum number of iterations\n",
    "\n",
    "    ########################################################################################### \n",
    "    for i in range(0, max):\n",
    "        print ('Iteration = ', i)\n",
    "        sum_convec = 0\n",
    "        # total converged eigenvectors\n",
    "        # breaf if sum_convec == k\n",
    "        \n",
    "        #################################################\n",
    "        # generate initial guess\n",
    "        if i == 0:\n",
    "            m, V, W = initial_guess(k)\n",
    "        print ('Initial guess done')\n",
    "        #################################################\n",
    "\n",
    "        sub_A = np.dot(V.T, W)  \n",
    "        # sub_A is subspace A matrix\n",
    "        sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "        # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "\n",
    "        lasit_newvec = 0\n",
    "        # amount of new vectors added in last iteration, ranging from 1 to k\n",
    "        # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "\n",
    "        \n",
    "        eigen_lambda = sub_eigenvalue[:k]\n",
    "        #diagonal elements are smallest k eigenvalues\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        for x in range(0,k):      \n",
    "            #looking at first k vecrors one by one, check whether they are roots\n",
    "            residual = np.dot((W[:,:m]- sub_eigenvalue[x]*V[:,:m].reshape(n,-1)), sub_eigenket[:,x])\n",
    "            # residual = A (Vs) - lambda*(Vs) \n",
    "            # Vs np.dotV([:,:m])s[:,x]), projects the subspace eigenket back to full space\n",
    "            \n",
    "            #print ('Residual created')\n",
    "        \n",
    "\n",
    "            norm = np.linalg.norm(residual)\n",
    "            if norm <= tol:\n",
    "                sum_convec += 1\n",
    "            else:\n",
    "                # current guess is not good enough, \n",
    "                # so we use current guess to create new guess vectors\n",
    "                #########################################################\n",
    "                new_vec = preconditioner (residual, sub_eigenvalue[x])          \n",
    "                #########################################################\n",
    "                # preconditioner\n",
    "                \n",
    "                new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "                new_vec = new_vec.reshape(-1,1)\n",
    "                # normalize before Gram-Schmidt \n",
    "                for y in range (0, m + lasit_newvec):  \n",
    "                    # orthonormalize the new vector against all old vectors\n",
    "                    new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y].reshape(-1,1)   \n",
    "                    \n",
    "                norm = np.linalg.norm (new_vec)\n",
    "                if norm > 1e-16:\n",
    "                    new_vec = new_vec/norm\n",
    "                    # normalzie the new vector, now Gram-Schmidt is done\n",
    "\n",
    "                    \n",
    "                    V = np.append (V, new_vec, axis=1)\n",
    "                    # put the new guess into container\n",
    "                    \n",
    "                    trans_new_vec = vind(new_vec)\n",
    "                    #print ('Shape of trans_new_vec =', np.shape(trans_new_vec)) = (1,351)\n",
    "                    W = np.append (W, trans_new_vec.T, axis = 1)\n",
    "                    # put transformed guess Av into container\n",
    "                    lasit_newvec += 1\n",
    "        ####################################################################################      \n",
    "        if sum_convec == k:\n",
    "            break\n",
    "        m += lasit_newvec\n",
    "    ########################################################################################### \n",
    "\n",
    "    Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "    \n",
    "    print ('Iteration steps =', i+1)\n",
    "    print ('Final subspace size = ', np.shape(sub_A))\n",
    "    #print ('Davidson time:', round(end-start,4))\n",
    "    \n",
    "    return (sub_eigenvalue[:k]*27.21138624598853, Eigenkets[:,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def Davidson (k, tol, initial_guess, preconditioner):\n",
    "\n",
    "    if initial_guess == 'sTDA_initial_guess':\n",
    "        initial_guess = sTDA_initial_guess\n",
    "        print ('Initial guess: sTDA A matrix')\n",
    "    elif initial_guess == 'A_diag_initial_guess':\n",
    "        initial_guess = A_diag_initial_guess\n",
    "        print ('Initial guess: Diagonal of Pseudo A matrix')\n",
    "        \n",
    "    if preconditioner == 'sTDA_fly_preconditioner':\n",
    "        preconditioner = preconditioner_sTDA\n",
    "        print ('Preconditioner: on-the-fly sTDA A matrix')\n",
    "        \n",
    "    elif preconditioner == 'full_sTDA_preconditioner':\n",
    "        preconditioner = sTDA_preconditioner\n",
    "        print ('Preconditioner: full sTDA A matrix')\n",
    "        \n",
    "    elif preconditioner == 'A_diag_preconditioner':\n",
    "        preconditioner = A_diag_preconditioner\n",
    "        print ('Preconditioner: Diagonal of Pseudo A matrix')\n",
    "    start = time.time()\n",
    "    \n",
    "    #tol = 1e-5      \n",
    "    # Convergence tolerance\n",
    "    n = occupied*virtual\n",
    "    max = 90      \n",
    "    # Maximum number of iterations\n",
    "\n",
    "    ########################################################################################### \n",
    "    for i in range(0, max):\n",
    "        print ('Iteration = ', i)\n",
    "        sum_convec = 0\n",
    "        # total converged eigenvectors\n",
    "        # breaf if sum_convec == k\n",
    "        \n",
    "        #################################################\n",
    "        # generate initial guess\n",
    "        if i == 0:\n",
    "            m, V, W = initial_guess(k)\n",
    "        print ('Initial guess done')\n",
    "        #################################################\n",
    "\n",
    "        sub_A = np.dot(V.T, W)  \n",
    "        # sub_A is subspace A matrix\n",
    "        sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "        # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "\n",
    "        lasit_newvec = 0\n",
    "        # amount of new vectors added in last iteration, ranging from 1 to k\n",
    "        # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "\n",
    "        \n",
    "        ####################################################################################\n",
    "        for x in range(0,k):      \n",
    "            #looking at first k vecrors one by one, check whether they are roots\n",
    "            residual = np.dot((W[:,:m]- sub_eigenvalue[x]*V[:,:m].reshape(n,-1)), sub_eigenket[:,x])\n",
    "            # residual = A (Vs) - lambda*(Vs) \n",
    "            # Vs np.dotV([:,:m])s[:,x]), projects the subspace eigenket back to full space\n",
    "            \n",
    "            #print ('Residual created')\n",
    "        \n",
    "\n",
    "            norm = np.linalg.norm(residual)\n",
    "            if norm <= tol:\n",
    "                sum_convec += 1\n",
    "            else:\n",
    "                # current guess is not good enough, \n",
    "                # so we use current guess to create new guess vectors\n",
    "                #########################################################\n",
    "                new_vec = preconditioner (residual, sub_eigenvalue[x])          \n",
    "                #########################################################\n",
    "                # preconditioner\n",
    "                \n",
    "                new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "                new_vec = new_vec.reshape(-1,1)\n",
    "                # normalize before Gram-Schmidt \n",
    "                for y in range (0, m + lasit_newvec):  \n",
    "                    # orthonormalize the new vector against all old vectors\n",
    "                    new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y].reshape(-1,1)   \n",
    "                    \n",
    "                norm = np.linalg.norm (new_vec)\n",
    "                if norm > 1e-16:\n",
    "                    new_vec = new_vec/norm\n",
    "                    # normalzie the new vector, now Gram-Schmidt is done\n",
    "\n",
    "                    \n",
    "                    V = np.append (V, new_vec, axis=1)\n",
    "                    # put the new guess into container\n",
    "                    \n",
    "                    trans_new_vec = vind(new_vec)\n",
    "                    #print ('Shape of trans_new_vec =', np.shape(trans_new_vec)) = (1,351)\n",
    "                    W = np.append (W, trans_new_vec.T, axis = 1)\n",
    "                    # put transformed guess Av into container\n",
    "                    lasit_newvec += 1\n",
    "        ####################################################################################      \n",
    "        if sum_convec == k:\n",
    "            break\n",
    "        m += lasit_newvec\n",
    "    ########################################################################################### \n",
    "\n",
    "    Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "\n",
    "    \n",
    "    print ('Iteration steps =', i+1)\n",
    "    print ('Final subspace size = ', np.shape(sub_A))\n",
    "    #print ('Davidson time:', round(end-start,4))\n",
    "    \n",
    "    return (sub_eigenvalue[:k]*27.21138624598853, Eigenkets[:,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('#################################################################')\n",
    "print ('In-house Davdison codes:')\n",
    "\n",
    "k = 40\n",
    "tol = 1e-5\n",
    "# initial_guess = 'sTDA_initial_guess'\n",
    "# preconditioner = 'sTDA_fly_preconditioner'\n",
    "\n",
    "print ('Number of excited states =', k)\n",
    "print ('Residual convergenve threshold =', tol)\n",
    "\n",
    "print ('#################################################################')\n",
    "\n",
    "start = time.time()\n",
    "Excitation_energies, kets = Davidson (k, tol, 'sTDA_initial_guess', 'sTDA_fly_preconditioner')\n",
    "end = time.time()\n",
    "\n",
    "print ('In-house Davidson time= ', end - start)\n",
    "print ('Excited State energies (eV) =')\n",
    "print (Excitation_energies)\n",
    "print ('#################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('PySCF TDA-TDDFT codes:')\n",
    "start = time.time()\n",
    "td.nstates = k\n",
    "td.kernel()\n",
    "end = time.time()\n",
    "print ('PySCF Davidson time= ', end - start)\n",
    "print ('#################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('#################################################################')\n",
    "start = time.time()\n",
    "Excitation_energies, kets = Davidson (k, tol, 'A_diag_initial_guess', 'A_diag_preconditioner')\n",
    "end = time.time()\n",
    "\n",
    "print ('In-house Davidson time= ', end - start)\n",
    "print ('Excited State energies (eV) =')\n",
    "print (Excitation_energies)\n",
    "print ('#################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQ (atom_id):\n",
    "    q = np.zeros([N_bf, N_bf])\n",
    "    #N_bf is number Atomic orbitals, q is same size with C\n",
    "    \n",
    "    C = coefficient_matrix ()\n",
    "    for i in range (0, N_bf):\n",
    "        for p in range (0, N_bf):\n",
    "            for mu in range (0, N_bf):\n",
    "                if AO[mu] == atom_id:\n",
    "                    #collect all basis functions centered on atom_id\n",
    "                    # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "                    q[i,p] += C[mu,i]*C[mu,p]\n",
    "                    #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "    return q\n",
    "\n",
    "# home_made population analysis\n",
    "# for atom_id in range (0, Natm):\n",
    "#     print (check_symmetric(Qmatrix[atom_id], tol=1e-12))\n",
    "#     m = 0\n",
    "#     for i in range (0, occupied):\n",
    "#         m += Qmatrix[atom_id][i,i]\n",
    "#         #sum over occupied orbitals\n",
    "#     print (m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Qmatrix = [(generateQ(atom_id)) for atom_id in range (0, Natm)]\n",
    "#a list of q matrix\n",
    "end = time.time()\n",
    "\n",
    "Qmatrix = np.asarray(Qmatrix)\n",
    "print (end - start)\n",
    "print (np.shape(Qmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define two electron intergeral (pq|rs)\n",
    "Natm = mol.natm \n",
    "#number of atoms\n",
    "Natm = mol.natm \n",
    "\n",
    "def ele_intJ (i,j,a,b):\n",
    "    ijab = 0\n",
    "    for atom_A_id in range (0, Natm):\n",
    "        for atom_B_id in range (0, Natm):\n",
    "            ijab += Qmatrix[atom_A_id,i,j] * Qmatrix[atom_B_id,a,b] * GammaJ[atom_A_id, atom_B_id]\n",
    "    return ijab\n",
    "        \n",
    "def ele_intK (i,a,j,b):\n",
    "    iajb = 0\n",
    "    for atom_A_id in range (0, Natm):\n",
    "        for atom_B_id in range (0, Natm):\n",
    "            iajb += Qmatrix[atom_A_id,i,a] * Qmatrix[atom_B_id,j,b] * GammaK[atom_A_id, atom_B_id]\n",
    "    return iajb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build A matrix\n",
    "def build_sTDA_A ():\n",
    "    A = np.zeros ([occupied*virtual, occupied*virtual])\n",
    "    m = -1\n",
    "    for i in range (0, occupied):\n",
    "        for a in range (occupied, N_bf):\n",
    "            m += 1 #for each ia pair, it corresponds to a certain row\n",
    "            n = -1\n",
    "            for j in range (0, occupied):\n",
    "                for b in range (occupied, N_bf):\n",
    "                    n += 1 #for each jb pair, it corresponds to a certain column        \n",
    "                    if i==j and a==b:\n",
    "                        A[m,n] =   2*ele_intK(i,a,j,b) - ele_intJ(i,j,a,b) + (MOe[a]-MOe[i]) \n",
    "                    else:\n",
    "                        A[m,n] = 2*ele_intK(i,a,j,b) - ele_intJ(i,j,a,b)\n",
    "    print ('sTDA_A matrix built, size =', np.shape(A)[0])\n",
    "    return A\n",
    "\n",
    "start = time.time()\n",
    "sTDA_A = build_sTDA_A ()\n",
    "end = time.time()\n",
    "print ('A_sTDA building time =', round (end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sTDA_A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigv,eigk = np.linalg.eigh(sTDA_A)\n",
    "print (eigv[:5]*27.21138624598853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (check_symmetric(A, tol=1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.linalg.norm(sTDA_A - sTDA_fly(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natm = mol.natm \n",
    "# def generateQ_ij ():\n",
    "#     q = np.zeros([Natm, occupied, occupied])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, occupied):\n",
    "#             for p in range (0, occupied):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu,i]*C[mu,p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# def generateQ_ab ():\n",
    "#     q = np.zeros([Natm, virtual, virtual])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, virtual):\n",
    "#             for p in range (0, virtual):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu, occupied + i]*C[mu,occupied + p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# def generateQ_ia ():\n",
    "#     q = np.zeros([Natm, occupied, virtual])\n",
    "#     C = coefficient_matrix ()\n",
    "#     for atom_id in range (0, Natm):\n",
    "#         for i in range (0, occupied):\n",
    "#             for p in range (0, virtual):\n",
    "#                 for mu in range (0, N_bf):\n",
    "#                     if AO[mu] == atom_id:\n",
    "#                         #collect all basis functions centered on atom_id\n",
    "#                         # the last loop is to sum up all C_mui*C_mup, calculate element q[i,p]\n",
    "#                         q[atom_id,i,p] += C[mu,i]*C[mu, occupied + p]\n",
    "#                         #q[i,p] += 2*C[i,mu]*C[p,mu]\n",
    "#     return q\n",
    "\n",
    "# start = time.time()\n",
    "# q_tensor_ij = generateQ_ij ()\n",
    "# q_tensor_ab = generateQ_ab ()\n",
    "# q_tensor_ia = generateQ_ia ()\n",
    "\n",
    "# end = time.time()\n",
    "# print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(A)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigv,eigk = np.linalg.eigh(A)\n",
    "# idx = eigv.argsort()\n",
    "# eigv = eigv[idx]    #eigenvalues\n",
    "# eigk = eigk[:,idx]          #eigenkets, m*m\n",
    "\n",
    "# #np.linalg.eigh guarantees you that the eigenvalues are sorted and uses a faster algorithm \n",
    "# #that takes advantage of the fact that the matrix is symmetric. \n",
    "\n",
    "# print (np.round (eigv[:10]*27.21138624598853,4))   \n",
    "# # ':n', first n elements; 'n:' all elements except firt n \n",
    "\n",
    "\n",
    "#methanol\n",
    "# a_x = 0.38\n",
    "# beta1= 1.86\n",
    "# beta2=0\n",
    "# alpha1= 0.9\n",
    "# alpha2=0\n",
    "#[12.2388 13.5994 13.7915 15.0407 15.1073 15.245  16.4534 16.5181 16.8506 17.3015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = tddft.TDA(mf)\n",
    "# td.nstates = 5\n",
    "# td.conv_tol = 1e-13\n",
    "# td.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energies, vectors = np.linalg.eigh(H)\n",
    "# print (energies[:5]*27.21138624598853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTDA_A = build_sTDA_A()\n",
    "## prepare sTDA_A matrix\n",
    "vind, hdiag = td.gen_vind(mf)\n",
    "n = len(hdiag)\n",
    "I = np.eye(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2O Excited State energies (eV)\n",
    "# [ 5.12051837  7.78183026  8.43305887  9.81364248 10.41186311]\n",
    "# [ 5.12051842  7.78183032  8.43305894  9.81364256 10.4118632 ]\n",
    "#\n",
    "\n",
    "\n",
    "#CH3OH Excited State energies (eV)\n",
    "#[ 8.73907144 10.77713239 11.26755041 12.203639   12.27658757]\n",
    "#[ 8.73907152 10.77713248 11.2675505  12.2036391  12.27658768]\n",
    "\n",
    "\n",
    "\n",
    "# CH3OH\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# sTDA A matrix as initial guess\n",
    "# sTDA A matrix as preconditioner\n",
    "# Iteration steps = 11\n",
    "# Davidson time: 0.3732\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# sTDA A matrix as initial guess\n",
    "# Diagonal of full A matrix as preconditioner\n",
    "# Iteration steps = 15\n",
    "# Davidson time: 0.3009\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# Diagonal of full A matrix as initial guess\n",
    "# Diagonal of full A matrix as preconditioner\n",
    "# Iteration steps = 15\n",
    "# Davidson time: 0.3152\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]\n",
    "\n",
    "\n",
    "# (351, 351)\n",
    "# sTDA_A matrix built\n",
    "# Diagonal of full A matrix as initial guess\n",
    "# sTDA A matrix as preconditioner\n",
    "# Iteration steps = 11\n",
    "# Davidson time: 0.334\n",
    "# Excitation_energies =\n",
    "# [ 8.73907152 10.77713248 11.2675505  12.2036391 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def davidson_A_matrix_hstack (A, k): # matrix A and how many eignvalues to solve\n",
    "    \n",
    "#     start = time.time()\n",
    "\n",
    "#     tol = 1e-5      # Convergence tolerance\n",
    "#     max = 40      # Maximum number of iterations\n",
    "\n",
    "#     ###########################################################################################\n",
    "#     # Begin iterations\n",
    "#     for i in range(0, max):\n",
    "#         sum_convec = 0\n",
    "#         #total converged eigenvectors\n",
    "#         # if sum_convec == k, break\n",
    "        \n",
    "#         lasit_newvec = 0\n",
    "#         # it records amount of new vectors added in last iteration, ranging from 1 to k\n",
    "#         # because not all new guess_vectors can survive the Gram-Schmidt\n",
    "        \n",
    "\n",
    "#         #################################################\n",
    "#         # generate initial guess\n",
    "#         if i == 0:\n",
    "#             #initial guess  \n",
    "#             n = np.shape(A)[0]\n",
    "#             m = k  \n",
    "#             # m is size of subspace Hamiltonian, amount of initial guesses   \n",
    "#             # m=k works for H2, m=4k works for H2O\n",
    "\n",
    "#             V = np.zeros((n, m)) #array of zeros, a container to hold current guess vectors\n",
    "            \n",
    "#             sort = np.diag(A).argsort()\n",
    "#             for j in range(0,m):\n",
    "#                 V[int(np.argwhere(sort == j)), j] = 1   \n",
    "#                 # positions with lowest values set as 1\n",
    "#             W = np.dot(A,V)   \n",
    "#             # W = Av, create transformed guess vectors\n",
    "#         #################################################\n",
    "        \n",
    "        \n",
    "#         sub_A = np.dot(V.T, W)  \n",
    "#         # sub_A is subspace A matrix\n",
    "#         sub_eigenvalue, sub_eigenket = np.linalg.eigh(sub_A) \n",
    "#         # Diagonalize the subspace Hamiltonian, and sorted.\n",
    "        \n",
    "        \n",
    "#         ####################################################################################\n",
    "#         for x in range(0,k):      \n",
    "#             #looking at first k vecrors one by one, check if they are roots\n",
    "#             residual = np.dot((W[:,:m]- sub_eiegnvalue[x]*V[:,:m]), sub_eigenket[:,x])\n",
    "#             # np.dotV([:,:m])s[:,x]) can transform the subspace-eigenket back into full space eigenket\n",
    "            \n",
    "#             norm = np.linalg.norm(residual)\n",
    "#             if norm <= tol:\n",
    "#                 sum_convec += 1\n",
    "#             else:\n",
    "#                 #print ('norm > tol')\n",
    "#                 # current guess is not good enough, \n",
    "#                 # so we use current guess to create new guess vectors\n",
    "#                 d = np.diag(A)-sub_eiegnvalue[x]\n",
    "#                 d[(d<1e-16)&(d>=0)] = 1e-16\n",
    "#                 d[(d>-1e-16)&(d<0)] = -1e-16   \n",
    "#                 # kick out all small values\n",
    "#                 new_vec = residual/d          \n",
    "#                 # preconditioner\n",
    "                \n",
    "#                 new_vec = new_vec/np.linalg.norm (new_vec) \n",
    "#                 # normalize before Gram-Schmidt \n",
    "\n",
    "#                 for y in range (0, m + lasit_newvec):  \n",
    "#                     # orthonormalize the new vector against all old vectors\n",
    "#                     new_vec = new_vec - np.dot(V[:,y], new_vec) * V[:,y]   \n",
    "                    \n",
    "#                 norm = np.linalg.norm (new_vec)\n",
    "#                 if norm > 1e-16:\n",
    "#                     new_vec = new_vec/norm\n",
    "#                     # normalzie the new vector, now Gram-Schmidt is done\n",
    "                    \n",
    "#                     V = np.append (V, new_vec[:, None], axis=1)\n",
    "#                     # put the new guess into container\n",
    "                    \n",
    "#                     W = np.append (W, np.dot(A, new_vec)[:, None], axis = 1)\n",
    "#                     # put transformed guess Av into container\n",
    "                    \n",
    "#                     lasit_newvec += 1\n",
    "#         ####################################################################################      \n",
    "#         if sum_convec == k:\n",
    "#             break\n",
    "#         m += lasit_newvec\n",
    "#     ########################################################################################### \n",
    "#     print ('Iteration steps =', i+1)\n",
    "\n",
    "#     end = time.time()\n",
    "#     Eigenkets = np.dot(V[:,:m], sub_eigenket[:, :k])\n",
    "#     print ('Davidson time (no vind function):', round(end-start,4))\n",
    "#     # return (sub_eiegnvalue[:k], Eigenkets[:,:k])\n",
    "#     return (sub_eiegnvalue[:k]*27.21138624598853)\n",
    "\n",
    "# #print (davidson_A_matrix_hstack (A, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nocc = mol.nelectron \n",
    "# mol.nelectron is number of electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
